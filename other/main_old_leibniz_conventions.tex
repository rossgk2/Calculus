\documentclass{article}
\usepackage{RNotation}

\begin{document}

\maketitle

\section*{To do}

\begin{itemize}
    \item define $\int g \spc df$ to mean fn and fn evaluated at $x$, determined by context

    \item incorporate ``$+ c$'' into integral notation.

    \item $\int \frac{1}{x} = \ln|x|$; tell a story
    
    \item investigate generalized binomial thm, and add combinatorics to precalc if necessary
    \item add pedagogical notes to calculus
    \begin{itemize}
        \item ``my approach'' vs. $\ln := \int_0 \frac{1}{x} dx = \lim_{a \rightarrow 0^+} \int_a \frac{1}{x} dx$.
        \item $\int f$ : $f'$, $\int f dx$ : $\frac{df}{dx}$, $\int f(x) dx$ : $\frac{df(x)}{dx} = f'(x)$
    \end{itemize}
    \item \sout{“df/dg is unconventional”}, “int f dg” is unconventional, “the above integration by parts formula is unconventional. The most understandable imitation of the usual convention is as follows…”
    \item b > 0 some places where unnecessary;rational extensions of ineqs unnecessary?;need to know $x -> e^x$ is a bijection onto (0, infty) in order to be able to know the inverse of $x -> b^x$ exists for every $b > 0$; can define logarithms to be inverse to exponentials over the rational numbers as a stepping stone 
    \item Can't define $b^{\frac{1}{x}}$ on all positive reals until we know $b^x$ maps to all positive reals. But we can make it work for positive rationals as a stepping stone.
    \item for precalc: define sin, sec, tan with geometric motivation. Then define ``trigonometric cofunction''. Then present cos, csc, cot. Note that while sin, sec, tan are how we started our, sin, cos, tan are most practically important. 
    \item post-composition essentially tells us to differentiate/integrate, and then plug in the function evaluated on the input 
\end{itemize}

\newpage

\part*{Differential calculus}

\section*{Foundations of calculus: limits and continuity}

\subsection*{What is calculus about?}

Calculus is about \textit{measuring change} by thinking about the infinitely small. All of calculus relies on intuition about ``infinitely small numbers'', or \textit{infinitesimals}.

In \textit{differential calculus}, the concept of infinitesimals is invoked in to measure the speed at which change occurs. If we want to measure the speed at which the output of a function $f$ is changing in response to a changing input, we can consider the rate of change of $f$ at the input $p$ to be the slope of the line that the curvy $f$ vs. $x$ graph ``becomes'' as we ``zoom in infinitely close'' to the point $(p, f(p))$.

In \textit{integral calculus}, we use infinitesimals to compute how much total change is caused by a given rate of change. If we want to determine how much total change has been caused by a rate of change that itself changes over time, we can think of the rate of change as being the aggregation of many rates of change that \textit{don't} change over time, where each of these rates occurs over an ``infinitely small'' window of input values, and then add up all of the little changes that result.

\subsection*{Limits}

The concept of ``infinitely small numbers'' is most often\footnote{There is another approach to formalizing the concept of ``infinitely small numbers'' called \textit{nonstandard analysis}. This approach is in some ways more intuitive because it literally does give a definition for ``infinitely small number''. On the other hand, nonstandard analysis requires that one drop the assumption that ``not false'' is equivalent to ``true''. Some may view this as a disadvantage. Nonstandard analysis also obscures the presence of ``error terms'' (terms that disappear in a limit taken to zero or infinity) that the limit approach makes obvious.} formalized with the concept of \textit{limits}. 

If, as inputs to a function $f$ that are \textit{greater} than a particular input $p$ get closer and closer to $p$, the outputs of $f$ get closer and closer to a number $L$, then we say ``the limit of $f$ as $x$ approaches $p$ from the right is $L$'', and write

\begin{align*}
    \lim_{x \rightarrow p^+} f(x) = L.
\end{align*}

The $+$ sign on the ``$p^+$'' below the limit indicates that the limit is taken ``from the right''; i.e., that the inputs that are getting closer to $p$ are all greater than $p$.

Similarly, if, as inputs of $f$ that are \textit{less} than $p$ get closer and closer to $p$, the outputs of $f$ get closer and closer to a number $M$, then we say ``the limit of $f$ as $x$ approaches $p$ from the left is $M$'', and write

\begin{align*}
    \lim_{x \rightarrow p^-} f(x) = M.
\end{align*}

The $-$ on the ``$p^-$'' below the limit indicates that the limit here is taken ``from the left''.

If the limits of $f$ at $p$ from the left and from the right are the same, then we define the so-called \textit{two sided limit} to be equal to the left and right limits\footnote{The colon-equals sign $:=$ is used here instead of a regular equals sign $=$ to indicate that the combination of symbols on the left side is being \textit{defined} to mean whatever is written on the right side. While some authors use the regular equals sign $=$ to denote definitions, I prefer to use the colon-equals $:=$ because I think it is important to disambiguate ``equality by definition'' from ``equality resulting from mathematical reasoning''.}:

\begin{align*}
    \lim_{x \rightarrow p} f(x) 
    := \lim_{x \rightarrow p^+} f(x) 
    = \lim_{x \rightarrow p^-} f(x).
\end{align*}

The lack of a $-$ or $+ $ sign on the ``$p$'' below the limit indicates that the limit is two-sided.

With the above formalism set up, expressions involving an ``infinitely small number'' $x$ can be reasoned about by considering limits of the form $\lim_{x \rightarrow 0} f(x)$; we can think of the $x$ in such limits as being ``infinitely close to zero''.

\subsubsection*{When limits don't exist}

It is not always the case that a given limit exists. 

A two-sided limit does not exist if its associated one-sided limits are not equal. When this is the case, and we have $\lim_{x \rightarrow p^-} f(x) \neq \lim_{x \rightarrow p^+} f(x)$, we say that $f$ has a \textit{jump discontinuity} at $p$.

Additionally, both two-sided and one-sided limits of a function $f$ at a point $p$ may fail to exist for the following reasons:

\begin{itemize}
    \item It may be the case that as inputs approach $p$, outputs only grow more and more positive or more and more negative. In these cases, the limit is considered to be \textit{infinite}, and we write something like ``$\lim_{x \rightarrow p} f(x) = \infty$'' or ``$\lim_{x \rightarrow p} f(x) = -\infty$''.
    \item It may be the case that as inputs approach\footnote{Consider $f(x) = \sin(2 \pi \omega(x) x)$, where $\omega(x) = (2 \pi x^2)^{-1}$. Since $\lim_{x \rightarrow 0^+} \omega(x) = \infty$, the graph of $f$ is a sine wave whose oscillation frequency approaches infinity as $x \rightarrow 0^+$. Thus, $f(x)$ oscillates widely as $x \rightarrow 0^+$. This implies that $f(x)$ doesn't get closer to any particular value as $x \rightarrow 0^+$, i.e., that $\lim_{x \rightarrow 0^+} f(x)$ does not exist.} $p$, the outputs oscillate and do not settle around any particular number.
\end{itemize}

\subsubsection*{Relationship between infinite and zero limits}

It's worth noting that the statement $(\lim_{x \rightarrow p} f(x) = - \infty \text{ or } \lim_{x \rightarrow p} f(x) = \infty)$ is true exactly when $\lim_{x \rightarrow p} \frac{1}{f(x)} = 0$ is true.

\subsubsection*{Properties of limits}

The following properties of limits that we present (but do not prove) are hopefully somewhat intuitive.

\vspace{.25cm}

If $\lim_{x \rightarrow p} f(x)$ and $\lim_{x \rightarrow p} g(x)$ both exist, then

\begin{align*}
    \lim_{x \rightarrow p} (c f(x)) &= c \lim_{x \rightarrow p} f(x) \\
    \lim_{x \rightarrow p} (f(x) + g(x)) &= \lim_{x \rightarrow p} f(x) + \lim_{x \rightarrow p} g(x) \\
    \lim_{x \rightarrow p} (f(x) g(x)) &= \Big( \lim_{x \rightarrow p} f(x) \Big) \Big( \lim_{x \rightarrow p} g(x) \Big) \\
    \lim_{x \rightarrow p} \frac{f(x)}{g(x)} &= \frac{\lim_{x \rightarrow p} f(x)}{\lim_{x \rightarrow p} g(x)} \text{ when } \lim_{x \rightarrow p} g(x) \neq 0
\end{align*}

The first two properties are collectively referred to as \textit{the linearity of the limit operator}\footnote{The limit operator $\lim_{x \rightarrow p}$ can be considered to be a function that sends functions to real numbers. In general, if $\Phi$ is a function that accepts other functions as input, then $\Phi$ is said to be \textit{linear} if, for all functions $f, g$ and all real numbers $c$, we (1) have $\Phi(f + g) = \Phi(f) + \Phi(g)$ and (2) have $\Phi(cf) = c\Phi(f)$. You can check that $\lim_{x \rightarrow p}$ is a linear function in this sense.

It may seem a bit strange that such functions are called ``linear functions''- after all, what do they have to do with lines? For the answer to this question, you will want to take a course in \textit{linear algebra}. The short answer is: inputs to linear functions are themselves ``linear elements'', and linear functions by definition ``preserve the decomposition'' of linear elements; linear functions are called what they are because they play nicely with linear elements.}. The second two properties are called the \textit{product and quotient rules for limits}, respectively.
    
\subsubsection*{Limits at infinity}

Another useful notion brought to us by the intuition of limits\footnote{I'm hinting here that the technical mathematical definition of a limit at infinity ($\lim_{x \rightarrow \infty} f(x)$, $\lim_{x \rightarrow -\infty} f(x)$) is different than the technical mathematical definition of a limit at a point ($\lim_{x \rightarrow p} f(x)$). This is due to the fact that we have to make some formal interpretation of what we mean by $x \rightarrow \infty$ and $x \rightarrow -\infty$; this interpretation involves $|x|$ getting larger and larger, which is different than the ``getting closer and closer'' involved in the definition of limit at a point.} is that of a function's ``limits at infinity'', or ``end behavior''. The idea is that, for a function $f$, we write $\lim_{x \rightarrow \infty} f(x) = L$ if, as $x$ gets larger and larger, $f(x)$ gets closer and closer to a number $L$. Similarly, we write $\lim_{x \rightarrow -\infty} f(x) = M$ if, as $x$ gets lesser and lesser and veers off to negative infinity, $f(x)$ gets closer and closer to a number $M$. 

Geometrically, a function's limits at infinity are the horizontal lines that its graph approaches but never touches, i.e., the function's limits at infinity correspond to \textit{horizontal asymptotes}.

Using the definitions of limits at infinity presented above, it's possible to prove that

\begin{align*}
    \lim_{x \rightarrow \infty} \frac{1}{x} = 0 \text{ and } \lim_{x \rightarrow -\infty} \frac{1}{x} = 0. 
\end{align*}

Hopefully this is intuitive enough: make $x$ really really big, and $\frac{1}{x}$ becomes really really small.

It's also possible to prove that analogous rules hold for limits at infinity \textit{that exist} to the ones described above for limits at a point. Therefore, by the limit product rule for limits at infinity that exist, we have

\begin{align*}
    \lim_{x \rightarrow \infty} \frac{1}{x^c} = 0 &\text{ and } \lim_{x \rightarrow -\infty} \frac{1}{x^c} = 0 \text{ for any positive real number $c$}, \\
    \lim_{x \rightarrow \infty} x^{-c} = 0 &\text{ and } \lim_{x \rightarrow -\infty} x^{-c} = 0 \text{ for any negative real number $c$}.
\end{align*}

\subsubsection*{Limits at infinity of a rational function}

These new facts provide us a way to take the limits at infinity of a ``rational function'', which is a function defined by $x \mapsto \frac{P(x)}{Q(x)}$, where $P(x) = p_0 + p_1 x + p_2 x^2 + ... + p_n x^n$ and $Q(x) = q_0 + q_1 x + q_2 x^2 + ... + q_m x^m$ are degree $n$ and $m$ polynomials for some $n$ and $m$, respectively. In your precalculus class, you may have had to memorize rules about how the degrees of $P$ and $Q$ determine these limits. But no memorization of silly rules is necessary: when you want to determine end behavior, take limits and see what happens!

To illustrate the point, let's now examine the end behavior of $x \mapsto \frac{P(x)}{Q(x)}$ at positive infinity:

\begin{align*}
    \lim_{x \rightarrow \infty} \frac{P(x)}{Q(x)} 
    = \lim_{x \rightarrow \infty} \frac{p_0 + p_1 x + p_2 x^2 + ... + p_n x^n}{q_0 + q_1 x + q_2 x^2 + ... + q_m x^m} 
    = \lim_{x \rightarrow \infty} \frac{\sum_{i = 1}^n p_i x^i}{\sum_{j = 1}^m q_j x^j}.
\end{align*}

We now consider three cases. It is either the case that $n > m$, $n = m$, or $n < m$. We can actually ignore the case $n > m$, since we can obtain the result for this case by following an argument that is similar to the one used for the case $n < m$. So, we can assume $n < m$ and $n = m$, i.e. we can assume $n \leq m$.

At this point, we rewrite the inside of the limit:

\begin{align*}
    \lim_{x \rightarrow \infty} \frac{\sum_{i = 1}^n p_i x^i}{\sum_{j = 1}^m q_j x^j} 
    = \lim_{x \rightarrow \infty} \Big( \frac{\sum_{i = 1}^n p_i x^i}{\sum_{j = 1}^m q_j x^j} \cdot \frac{x^{-n}}{x^{-n}} \Big)
    = \lim_{x \rightarrow \infty} \Big( \frac{\sum_{i = 1}^n p_i x^{i - n}}{\sum_{j = 1}^m q_j x^{j - n}} \Big).
\end{align*}

Now, we will \textit{assume} that it is valid to apply the limit quotient rule and the linearity of the limit. (We will justify this assumption retroactively). The limit becomes

\begin{align*}
    \frac{\lim_{x \rightarrow \infty} \sum_{i = 1}^n p_i x^{i - n}}{\lim_{x \rightarrow \infty} \sum_{j = 1}^m q_j x^{j - n}}
    = \frac{\sum_{i = 1}^n p_i \lim_{x \rightarrow \infty} x^{i - n}}{\sum_{j = 1}^m q_j \lim_{x \rightarrow \infty} x^{j - n}}
\end{align*}

It is only valid to apply the limit quotient rule if the limit of the denominator in the first above equation is nonzero, and that it is only valid to apply the linearity of the limit if, for all $i$ and $j$, the limits in the sums of the second above equation exist or are infinite. Now comes the retroactive justification- as we continue our computations, we will see that all of these conditions are always satisfied\footnote{In general, if we want to use a theorem that is stated in the form ``$(\text{conditions}) \implies (\text{result})$'', it is not valid to deduce that the conditions follow as a consequence of assuming the result- this is circular reasoning. It may seem that we are doing this here, but we are actually not. It just so happens that with limit laws, the computations involved in the result are the same computations that are examined in the testing of conditions. So, we can get ahead of ourselves and compute the result while simultaneously checking the calculations to make sure that the conditions are satisfied.}.

Consider the case in which the degree of the ``top'' polynomial is lesser than the degree of the ``bottom'' polynomial, i.e., the case in which $n < m$. First, we compute the limits in the numerator. Since $i \leq n$ and $n < m$, we have $i < n \iff i - n < 0$ for all $i$. Knowing that $i - n$ is negative for all $i$ then gives us that $\lim_{x \rightarrow \infty} x^{i - n} = 0$ for all $i$, and so the numerator is $\sum_{i = 1}^m p_i \lim_{x \rightarrow \infty} x^{i - n} = \sum_{i = 1}^m (p_i \cdot 0) = 0$. As for the denominator, we know that for all $j$ we have $j < m \iff j - m < 0$, and thus $\lim_{x \rightarrow \infty} x^{j - m} = 0$ for all $j < m$. Thus, the denominator is 

\begin{align*}
    \sum_{j = 1}^m q_j \lim_{x \rightarrow \infty} x^{j - m} = \Big( \sum_{j < m} q_j \lim_{x \rightarrow \infty} x^{j - n} \Big) + q_m x^{m - m} = \sum_{j < m} (q_j \cdot 0) + q_m = q_m.
\end{align*}

Overall, we see that when $n < m$ the limit of the rational function is $\lim_{x \rightarrow \infty} \frac{P(x)}{Q(x)} = \frac{0}{q_m} = 0$. This means that when $n < m$ the graph of $\frac{P}{Q}$ has the horizontal asymptote $y = 0$. 

A similar argument as was used above shows that when $n > m$, the overall limit is $\lim_{x \rightarrow \infty} \frac{P(x)}{Q(x)} = \lim_{x \rightarrow \infty} \frac{R(x)}{S(x)}$, where $\lim_{x \rightarrow \infty} R(x) = p_n$ and $\lim_{x \rightarrow \infty} S(x) = 0$. From this it follows that $\lim_{x \rightarrow \infty} \frac{P(x)}{Q(x)} = \pm \infty$, where we determine whether $\pm$ is $+$ or $-$ by checking whether $\frac{P}{Q}$ is eventually\footnote{Graphs of polynomials may alternate between increasing and decreasing for a little while, but for every polynomial there must exist $a$ and $b$ such that the polynomial is either strictly increasing or decreasing on $(-\infty, a)$ and either strictly increasing or decreasing on $(b, \infty)$.} increasing or whether $\frac{P}{Q}$ is eventually decreasing as $x \rightarrow \infty$.

If $P$ and $Q$ have equal degrees and $n = m$, then the limit computation for the denominator is the same as the above. The limit computation for the numerator is analogous to the one for the denominator, so we end up with the overall limit $\lim_{x \rightarrow \infty} \frac{P(x)}{Q(x)} = \frac{p_n}{q_m}$. Thus, when $n = m$, the graph of $\frac{P}{Q}$ has a horizontal asymptote at $y = \frac{p_n}{q_m}$. 

This completes our analysis of all cases. Don't worry too much about the details of this derivation, and certainly do not try to memorize this derivation! If you take away anything from the above, just remember that you do \textit{not} have to memorize anything, and that you can determine the end behavior of a rational function by following a \textit{process} if need be. 

\subsection*{Continuity}

In calculus, the objects of study are what are called \textit{continuous functions}. Intuitively, continuous functions have graphs that are smooth and without gaps. We will use the mathematical tool of limits in order define what it really means for a function to be continuous:

\begin{itemize}
    \item We say that a function $f$ is \textit{continuous at a point} $p$ if $\lim_{x \rightarrow p} f(p)$ exists and $\lim_{x \rightarrow p} f(x) = f(p)$. 
    \item We say that a function $f$ is \textit{continuous everywhere}, or simply \textit{continuous}, if it is continous at every point in its domain.
\end{itemize}

It's instructive to think about how a function could fail to be continuous at a point $p$. There are two ways for a so-called \textit{discontinuity} to occur: either it is the case that $\lim_{x \rightarrow p} f(x)$ does not exist (recall, this could be due to a jump discontinuity, an infinite limit, or an oscillating limit), or it is the case that $\lim_{x \rightarrow p} f(x) \neq f(p)$. When the later occurs, $f$ is said to have a \textit{point discontinuity} at $p$. An example of a function that satisfies the later condition is defined by

\begin{align*}
    g(x) =
    \begin{cases}
        x & x \neq 0 \\
        1 & x = 0
    \end{cases}.
\end{align*}

In this case, we have $\lim_{x \rightarrow 0} g(x) = 0 \neq 1 = g(0)$, so $g$ has a removable discontinuity at $0$.

\subsubsection*{Limit of a composition}

If $\lim_{x \rightarrow p} f(x)$ exists and $g$ is continuous at $\lim_{x \rightarrow p} f(x)$, then

\begin{align*}
    {\lim_{x \rightarrow p} g(f(x)) = g(\lim_{x \rightarrow p}f(x))}.
\end{align*}

\newpage

\section*{Functions vs. functions evaluated on inputs}

Before we dive into calculus, we should review the difference between a \textit{functions} and a \textit{function evaluated on an input}.

\begin{itemize}
    \item A \textit{function} is an association between two sets in which every item from the set of ``inputs'' is associated with at most one item from the set of ``outputs''.
    \item A \textit{function evaluated on an input} is exactly what it sounds like- it is the result of taking an item from the function's associated input set and plugging it into the function. In other words, a function evaluated on an input is an ``output'' of the function.
\end{itemize}

For example: if $f$ is a function, and $x$ is an input, then $f(x)$ is a function evaluated on an input.

Oftentimes, people become sloppy and conflate the two notions. When someone writes, ``the function $a^2$'', they are using incorrect mathematical grammar, since $a^2$ is not a function, but instead the the result of evaluating the function $f$ defined by $f(x) = x^2$ on the input $a$. Saying ``let $f(a)$ be a function'' is also incorrect mathematical grammar, for the same reason.

\subsection*{Anonomyous functions}

It's really tedious to write things such as ``the function $f$ defined by $f(x) = x^2$'', so we introduce the following notation:

\begin{align*}
    \text{``}x \mapsto (\text{expression involving $x$}) \text{'' means ``the function sending $x$ to $(\text{expression involving $x$})$''}.
\end{align*}

Using the above notation, we can now say ``the function $x \mapsto x^2$'' instead of ``the function $f$ defined by $f(x) = x^2$''. This notation is called \textit{anonymous function notation} because it allows us to specify functions without giving them names such as $f$.

\subsection*{Physicists' conventions regarding functions}

Physicists often conflate functions with functions evaluated on inputs. There actually is a somewhat sensible way to do this conflation that can be useful, but this somewhat sensible way is rare, and you are much more likely to see a calculus or physics textbook saying nonsensical things like ``let $y = f(x)$'' or ``let $f = f(x)$''.

See the appendix for details on the somewhat sensible way.

\newpage

\section*{Introduction to derivatives}

\subsection*{The limit definition of the derivative}

Given a function $f$ that maps real numbers to real numbers, we define the \textit{derivative of $f$} to be the function $f'$ that is defined as follows:
     
\begin{align*}
     \boxed
     {
        f'(x) := \lim_{\Delta x \rightarrow 0} \frac{f(x + \Delta x) - f(x)}{\Delta x}
     }
\end{align*}

Note, we have used $:=$ instead of $=$ because we are stating a definition rather than proving an equality. Also note that the Greek capital delta, $\Delta$ is used because it is a symbol associated with changes in quantities; $\Delta x$ is thought of as a small change in input. 

It is entirely possible to write the definition of the derivative without using the $\Delta$ symbol. In fact, it is common to present the definition of the derivative using the letter $h$ in the place of $\Delta x$, as follows:

\begin{align*}
    f'(x) := \lim_{h \rightarrow 0} \frac{f(x + h) - f(x)}{h}.
\end{align*}

Here is how to interpret what $f'(x)$ means. Since $\Delta x$ goes to zero in the limit, we can imagine that $\Delta x$ is an ``infinitely small number''. Thus, $f(x + \Delta x) - f(x)$ is the change in the function $f$ that results from an infinitely small change in the input $x$. Dividing this infinitesimally small change in $f$ by the infinitesimally small change in input, $\Delta x$, intuitively gives the ``instantaneous rate of change'' of $f$ at $x$ that occurs due to the changing of the input from $x$ to $x + \Delta x$. For this reason, $f'(x)$ is often called the \textit{instantaneous rate of change of $f$ at $x$}.

Geometrically, the argument of the limit, $\frac{f(x + \Delta x) - f(x)}{\Delta x}$, is the slope of the so-called secant\footnote{A line is said to be \textit{secant} to a graph if it intersects the graph at two or more points.} line that passes through the points $(x, f(x))$ and $(x + \Delta x, f(x + \Delta x))$, since the ``rise over run'' ratio of this line is equal to the expression that is inside the above limit:

\begin{align*}
    \frac{f(x + \Delta x) - x}{(x + \Delta x) - x} = \frac{f(x + \Delta x) - x}{\Delta x}.
\end{align*}

When we take the limit $\Delta x \rightarrow 0$ of the slope of this secant line, the inputs $x$ and $x + \Delta x$ become infinitely close, and thus the points $(x, f(x))$ and $(x + \Delta x, f(x + \Delta x))$ become infinitely close. Intuitively, it should be clear that, if it exists, the limit approached by taking $\Delta x \rightarrow 0$ is the slope of the line that touches the graph of $f$ at the point $(x, f(x))$ and that ``aligns with the slope of the function's graph at that point''. We call this line the \textit{tangent line}\footnote{Though we were speaking of tangent lines to gain intuition about the derivative, if we are to be formal, then we actually use the derivative to define what it means for a line to be a tangent line. The \textit{tangent line} to the graph $f$ at $(x, f(x))$ is the line of slope $f'(x)$ that passes through $(x, f(x))$.} to $f$ at $(x, f(x))$.

\subsubsection*{Continuity is a requirement for differentiability}

[TO DO]

[diff => cont, but cont =/> diff]

\subsection*{Leibniz notation}
     
We now make two definitions. For any letter $x$ of the alphabet, we define:

\begin{align*}
    \frac{df}{dx} &:= f' \\
    \frac{df}{dx}\Big|_p &:= f'(p).
\end{align*}

That is, writing $\frac{df}{dx}$ means the same thing as writing $f'$, and writing $\frac{df}{dx}\Big|_p$ means the same as writing $f'(p)$.

The notations $f'$ and $f'(p)$ are said to be \textit{prime notation}, and the notations $\frac{df}{dx}$ and $\frac{df}{dx}\Big|_p$ are said to be \textit{Leibniz notation}.

Leibniz notation makes derivatives \textit{appear} to be fractions. This helps with intuition a lot. You can informally think of $\frac{df}{dx}$ as corresponding to dividing an infinitesimal ``rise'' at $p$, $df|_p$, by the infinitesimal ``run'' at $p$, $dx|_p$, to get $(\text{instantaneous slope at $p$)} = \frac{\text{infinitesimal rise}}{\text{infinitesimal run}} = \frac{df}{dx}\Big|_p$. This is the idea that is formalized in the definition of the derivative as a limit.

It is important to emphasize that, on a purely formal level, the $x$ in the ``denominator'' of the above definition is not a real number- it is just a letter of the alphabet. So, we have $\frac{df}{dx} = \frac{df}{da} = \frac{df}{db} = \frac{df}{dc} = ... = \frac{df}{dz}$. However, because we like to think of $dx$ as being an ``infinitesimally small'' change in the input to $f$, we often choose to pretend that the symbol in the ``denominator'' is a real number, even though it technically isn't. 

We will typically use $x$ in the ``denominator'' as a convention.

\vspace{.5cm}

\textbf{Important: the most common abuse of Leibniz notation.}

There is a difference between a function, such as $f'$, and the result of evaluating a function on an input, such as $f'(p)$. In spite of this, people often write $\frac{df}{dx}$ to mean either $f'$ or $f'(x)$, even though, \textit{technically}, $\frac{df}{dx}$ can only mean $f'$.

Since this abuse of notation is so common\footnote{Some people try to solve this issue by using the definitions $\frac{df}{dx} := f'$ and $\frac{df}{dx}(x) := f'(x)$, but I feel that this makes things more confusing, as $\frac{df}{dx}(x)$ can be misinterpreted as ``$\frac{df}{dx}$ times $x$.''}, we slightly revise our definition of $\frac{df}{dx}$, and define

\begin{align*}
    \boxed
    {
        \frac{df}{dx} := \begin{cases} f' \\ f'(x) \end{cases}, \text{ where the choice is determined from context}
    }
\end{align*}

We now give some examples of the ``context'' mentioned in the above equation. There are three general scenarios to cover. The first scenario is when we have an equation written as

\begin{align*}
    \frac{df}{dx} = \text{some expression involving a function $g$}.
\end{align*}

In this scenario, since the right side of the equation involves a function, not a function evaluated on an input, we must interpret $\frac{df}{dx}$ to be a function as well; we are forced to interpret $\frac{df}{dx}$ as $\frac{df}{dx} = f'$.

The second scenario arises when we encounter an equation written as

\begin{align*}
    \frac{df}{dx} = \text{some expression involving $g(x)$, where $g$ is a function}.
\end{align*}

Since the above right side involves a function evaluated on an input, not a function, we must interpret $\frac{df}{dx}$ to mean $\frac{df}{dx} = f'(x)$.

The third scenario is when we have an equation written as

\begin{align*}
    \frac{df}{dx} = \text{some expression involving $\frac{dg}{dx}$, where $g$ is a function}.
\end{align*}

In this scenario, we are free to interpret $\frac{df}{dx}$ and $\frac{dg}{dx}$ as functions ($\frac{df}{dx} = f'$ and $\frac{dg}{dx} = g'$), or as functions evaluated on inputs ($\frac{df}{dx} = f'(x)$ and $\frac{dg}{dx} = g'(x)$). It doesn't matter which interpretation we use in this case, as the above equation will mean the same thing regardless\footnote{This is because $f = g$ exactly when $f(x) = g(x)$ for all $x$.}.

\subsection*{More on derivative notation}

\indent \textbf{The advantage of prime notation; on functions versus functions evaluated at inputs.} 
         
In light of the above ``most common abuse of Leibniz notation'', prime notation is best for illustrating the fact that the derivative $f'$ of a function $f$ is itself a function. Leibniz notation does not address this subtlety, because the symbol $\frac{df}{dx}$ can mean either $f'$ (which is a function) or $f'(x)$ (which is a function evaluated at an input).

\vspace{.5cm}

\textbf{Advantages of Leibniz notation.} 
         
Despite the discussion above, you should use Leibniz notation, because, as mentioned before,  it makes derivatives \textit{appear} to be fractions. This helps with intuition a lot.
         
One important example of this is that Leibniz notation can also help you remember the units of a derivative. For example, if the output of $f$ has units of length, and the input $x$ of $f$ has units of time, then you can reason that the tiny increments in $f$ and $x$, $df$ and $dx$, must also have units of length and time, respectively. This lets you realize that $\frac{df}{dx}$ has units of $\frac{\text{length}}{\text{time}}$.
         
Lastly, Leibniz notation helps you to remember the \textit{chain rule} for derivatives. The chain rule, written sloppily, is: $\frac{dg}{dx} = \frac{dg}{df} \frac{df}{dx}$. Notice that it \textit{looks like} the $df$'s on the right side cancel with each other to give the left side.
         
\vspace{.5cm}     
    
\textbf{The derivative as an operator.}
         
You can write $f'$ and $f'(x)$ in ``operator'' notation with the following two new definitions:

\begin{align*}
    \frac{d}{dx}f &:= f' \\ \frac{d}{dx} f(x) &:= f'(x).
\end{align*}

Writing things in the way of the above emphasizes the fact that $\frac{d}{dx}$ is itself a sort of function: it is a function that takes functions ($f$) as input and returns functions ($f'$) as output.
         
In practice, the definition $\frac{d}{dx} f(x) := f'(x)$ means that an expression such as $\frac{d}{dx}(x^2)$ is syntactically valid, even though $x^2$ is a function evaluated on a input and is not a function itself. Specifically, it tells us\footnote{Recall that $x \mapsto x^2$ is a way of writing ``the function that sends $x$ to $x^2$''. The $|_x$ in $\Big( \frac{d}{dx}(x \mapsto x^2)\Big)\Big|_x$ means ``evaluate $\frac{d}{dx}(x \mapsto x^2)$ at $x$''.} that $\frac{d}{dx}(x^2) = \Big( \frac{d}{dx}(x \mapsto x^2)\Big)\Big|_x$.

\vspace{.5cm}

\textbf{More Leibniz notation: $\frac{df(x)}{dx}$.}
         
We define 

\begin{align*}
    \frac{df(x)}{dx} := \frac{d}{dx} f(x) = f'(x).
\end{align*}

Before now, we hadn't defined what it means yet for a function evaluated on an input to appear in the ``numerator'' in Leibniz notation.

Note that the symbol inside the parentheses of the ``numerator'' must be the same as the symbol in the ``denominator'' for this notation to mean what you expect; otherwise, for $x \neq p$, we have $\frac{df(p)}{dx} = \frac{d}{dx} f(p) = \frac{d}{dx} (\text{const}) = 0$.
         
\section*{Some first differentiation formulas}

Now that we have developed some sense of the various derivative notations, we are ready to derive (i.e. prove) some facts that allow us to compute derivatives of complicated expressions by means of computing derivatives of simpler sub-expressions.

In this section- and book in general- I am not a stickler about stating the conditions that must be satisfied for a fact about derivatives to be applicable. I will make note of conditions when doing derivations, but will not restate them in final ``boxed'' formulas. Focusing on such conditions is not really relevant for an introduction to calculus, and, anyways, the conditions are usually self-evident from the formula in question. If a derivative formula involves some derivative $g'(x)$, well, then one of the conditions is probably ``$g$ is differentiable''!

\subsection*{The power rule}

The derivative formula that pretty much everyone learns first is the formula for $\frac{d}{dx} x^n$.

[PROOF: TO-DO].

\begin{align*}
    \frac{d}{dx} x^n = nx^{n - 1} \text{ for any integer $n$}
\end{align*}

Can be extended to work for real numbers, not just integers. [See appendix].

\begin{align*}
    \boxed
    {
        \frac{d}{dx} x^c = cx^{c - 1} \text{ for any real number $c$}
    }
\end{align*}

For example, $\frac{d}{dx} x^{\frac{1}{2}} = \frac{1}{2}x^{-\frac{1}{2}}$ and that $\frac{d}{dx} x^\pi = \pi x^{\pi - 1}$.

\subsection*{Linearity of the derivative}

Using the definition of the derivative, you can prove the following.

For any functions $f, g$,
\begin{align*}
    \frac{d}{dx}(cf(x)) &= c \frac{d}{dx}(f(x)) \text{ for any real number $c$} \\
    \frac{d}{dx}(f(x) + g(x)) &= \frac{d}{dx}(f(x)) + \frac{d}{dx}(g(x))
\end{align*}

Recall the notion of \textit{scaling a function by a real number} and of \textit{adding two functions together}: if $r, s$ are functions and $d$ is a real number, then $dr$ is the function defined by $(dr)(x) := dr(x)$ and $r + s$ is the function defined by $(r + s)(x) := r(x) + s(x)$. Using this notation, the above can be restated as follows. 

For any functions $f, g$,

\begin{empheq}[box = \fbox]{align*}
    \frac{d}{dx}(cf) &= c \frac{d}{dx}(f) \text{ for any real number $c$} \\
    \frac{d}{dx}(f + g) &= \frac{d}{dx}(f) + \frac{d}{dx}(g)
\end{empheq}

\subsection*{Product rule}

\begin{empheq}[box = \fbox]{align*}
    \frac{d}{dx}(fg) = \frac{df}{dx} g + f \frac{dg}{dx} = f'g + fg'
\end{empheq}

\subsection*{The chain rule}

When given functions $f, g$, there is a function called the \textit{composition of $g$ with $f$} that is denoted by $g \circ f$ and defined by $(g \circ f)(x) := g(f(x))$. Put simply, $g \circ f$ is the function that represents what happens if you wrap the result of doing $f$ and then $g$ into a single process.

The chain rule tells us how to relate the derivative of $g \circ f$ of the derivatives of $g$ and $f$. In prime notation, it is as follows:

\begin{align*}
    (g \circ f)'(x) = (g' \circ f)(x) f'(x) &= g'(f(x)) f'(x).
\end{align*}

We see that the instantaneous rate of change of a composition of functions at a point is the instantaneous rate of change of the ``outer function'', $g$, at the input that $g$ receives from $f$, times the instantaneous rate of change of the ``inner function'', $f$, at the input $f$ receives. Thus, the rate of change of $g \circ f$ at a point is proportional to the instantaneous rates of change of $g$ and $f$ at the ``relevant'' inputs (those being $f(x)$ and $x$, respectively).

The above presentation of the chain rule is probably the best version of the chain rule to learn first, as it is most ``to the point'', but it is not the most elegant.

\subsubsection*{The chain rule as a ``cancellation of fractions''.}

To advance towards the most elegant presentation of the chain rule, we first restate the chain rule as:

\begin{align*}
    (g \circ f)' = (g' \circ f) f'.
\end{align*}

In the above, we have used the notion of a product of functions; $(g' \circ f)f'$ denotes the function defined by $((g' \circ f)f')(x) = (g' \circ f)(x)f'(x)$. (See the previous section on the product rule to review this). We then of course have $(g' \circ f)(x)f'(x) = g'(f(x))f'(x)$ due to the definition of function composition $\circ$.

Slightly rewriting the above, we write $f'$ as $\frac{df}{dx}$ and obtain

\begin{align*}
    \frac{d(g \circ f)}{dx} = (g' \circ f)\frac{df}{dx}.
\end{align*}

Now, when given functions $g$ and $f$, we \textit{define} $\frac{dg}{df}$ to be the function\footnote{Note that this definition gives importance to the letter used in the denominator. So, if $a, b, c, ..., z$ are distinct functions, then $\frac{dg}{da} \neq \frac{dg}{da} \neq \frac{dg}{db} \neq \frac{dg}{dc} = ... \neq \frac{dg}{dz}$. On the other hand, if the letters $a, b, c, ..., z$ are not the names of a function, then the letter in the ``denominator'' does not matter, and we have $\frac{dg}{da} = \frac{dg}{da} = \frac{dg}{db} = \frac{dg}{dc} = ... = \frac{dg}{dz}$. But we will not make use of this technical fact, and will stick to using $x$ to represent a not-function in the denominator.}

\begin{align*}
    \frac{dg}{df} := g' \circ f.
\end{align*}

We denote the expression $g' \circ f$ by $\frac{dg}{df}$ because one way to evaluate $\frac{dg}{df} = g' \circ f$ at an input $x$ is to first compute $g'(f)$ and to then substitute $f(x)$ in for $f$:

\begin{align*}
    \frac{dg}{df}\Big|_x = g'(f(x)) = g'(f)|_{f \rightarrow f(x)}. 
\end{align*}

With this new notation, we see the most recent restatement of the chain rule becomes

\begin{align*}
    \frac{d (g \circ f)}{dx} = \frac{dg}{df} \frac{df}{dx}, \text{ where $\frac{dg}{df} := \frac{dg}{dx} \circ f = g' \circ f$}.
\end{align*}

Now, if we squint, and pretend that the left side is just $\frac{dg}{dx}$, then the chain rule becomes ``$\frac{dg}{dx} = \frac{dg}{df}\frac{df}{dx}$'', so it looks like the $df$'s on the right hand side are canceling in a multiplication of fractions.

You are probably wondering: ``why would it make sense to think of $\frac{d (g \circ f)}{dx}$ as being equal to $\frac{dg}{dx}$?''. Well, in a purely formal sense, it is of course \textit{not} true that for arbitrary functions $f$ and $g$ we will have $\frac{d (g \circ f)}{dx} = \frac{dg}{dx}$. However, it does make some sense to conflate the two notions- see the appendix to learn why.

\vspace{.5cm}

\textbf{In summary, here are four ways to state the chain rule.}
         
\begin{empheq}[box = \fbox]{align*}
    (g \circ f)'(x) &= (g' \circ f)(x) f'(x) = g'(f(x)) f'(x) \text{ for all $x$} \\
    (g \circ f)' &= (g' \circ f) f' \\
    \frac{d (g \circ f)}{dx}\Big|_x &= \frac{dg}{df}\Big|_x \frac{df}{dx}\Big|_x = \frac{dg}{dx}\Big|_{f(x)} \frac{df}{dx}\Big|_x \text{ for all $x$} \\
    \frac{d (g \circ f)}{dx} &= \frac{dg}{df} \frac{df}{dx}, \text{ where } \frac{dg}{df} := \frac{dg}{dx} = g' \circ f 
\end{empheq}

I should mention that the definition $\frac{dg}{df} := g' \circ f$ is unconventional; you will be hard pressed to find another calculus text that makes this same definition. However, physics texts implicitly rely on this definition all the time.

\subsubsection*{A bad way to state the chain rule}

Most calculus textbooks state the chain rule as follows:

\begin{align*}
    \text{``}\frac{dg(f(x))}{dx} = \frac{dg}{du} \frac{du}{dx}, \text{ where $u = f(x)$}\text{''}.
\end{align*}

The main problem that underlies this notation is the conflation of a \textit{particular} number $u$ with a \textit{function} $f$. The phrase ``where $u = f(x)$'' is meant to indicate that $u$ is to be conflated with $f$ in some random, confusing way that doesn't make sense on a whole lot of levels:

\begin{itemize}
    \item Since $x$ is a particular number\footnote{The $x$ in the statement ``$u = f(x)$'' must represent some particular number. Yes, it's true that $x$ may be an \textit{arbitrary} particular number, but it still has to be one single number- $x$ cannot magically be many numbers at once, even though the bad notation may suggest so.}, $f(x)$ also be a particular number, and so $\frac{du}{dx} = \frac{df(x)}{dx} = \frac{d}{dx}(\text{constant}) = 0$. Obviously, $\frac{d}{dx}g(f(x))$ is not always zero! 
    \item If you try to substitute $f(x)$ in for $u$, which seems like a reasonable thing to do, you get the expression $\frac{dg}{df(x)}$, which doesn't have any meaning.
\end{itemize}

The above notation \textit{only works if you have explicit formulas for $g$ and $f$}, and even then, you are only allowed to substitute $f(x)$ in for $u$ \textit{after} you have computed an explicit formula for $\frac{dg}{du}$. So, please don't try to understand the above notation. Just know that it's very commonly used but very bad.

\subsection*{More derivative formulas}

\subsubsection*{Quotient rule}

When $g(x) \neq 0$, we can use the product rule to compute the derivative of $\frac{f}{g} =  \frac{1}{g}$, where $\frac{1}{g}\Big|_x := \frac{1}{g(x)}$, and so obtain a \textit{quotient rule}:

\begin{align*}
    \frac{d}{dx}\Big(\frac{f}{g}\Big)\Big|_x
    &= \frac{d}{dx}\Big(f \frac{1}{g} \Big)\Big|_x  = \frac{df}{dx}\Big|_x \frac{1}{g(x)} + f(x) \frac{d}{dx}\Big(g(x)^{-1} \Big) \text{ when $g(x) \neq 0$}.
\end{align*}

The chain rule [haven't proved this yet] gives

\begin{align*}
    \frac{d}{dx}\Big(g(x)^{-1} \Big) = -g(x)^{-2}g'(x) = -\frac{g'(x)}{g(x)^2} \text{ when $g(x) \neq 0$},
\end{align*}

so the above is

\begin{align*}
    \frac{d}{dx}\Big(\frac{f}{g}\Big)\Big|_x
    = f'(x)\frac{1}{g(x)} - f(x)\frac{g'(x)}{g(x)^2} = \frac{f'(x)g(x) - f(x)g'(x)}{g(x)^2} \text{ when $g(x) \neq 0$}.
\end{align*}

In all, we have that for all functions $f, g$:

\begin{empheq}[box = \fbox]{align*}
    \frac{d}{dx}(fg) &= \frac{df}{dx} g + f \frac{dg}{dx} = f'g + fg' \\
    \frac{d}{dx}\Big(\frac{f}{g}\Big)\Big|_x &= \frac{f'(x)g(x) - f(x)g'(x)}{g(x)^2} \text{ when $g(x) \neq 0$}.
\end{empheq}

\subsubsection*{Derivatives of trig functions}

We now compute the derivatives of the trig functions $\sin, \cos, \tan$. We do so by finding the derivative of $\sin$ and then using trig identities and derivative formulas to infer the derivatives of $\cos$ and $\tan$.

Before we compute the derivative of $\sin$, we need to know that $\lim_{x \rightarrow 0} \frac{\sin(x)}{x} = 1$ and that $\lim_{x \rightarrow 0} \frac{\cos(x) - 1}{x} = 0$. The squeeze theorem can be used to prove\footnote{\url{https://proofwiki.org/wiki/Limit_of_(Cosine_(X)_-_1)_over_X/Proof_3} for the proof that $\lim_{x \rightarrow 0} \frac{\cos(x) - 1}{x} = 0$.} the first fact, and the first fact in combination with the identity $\cos(x) = \sin(x - \frac{\pi}{2})$ can be used to prove the second fact. 

Knowing these facts, we can use the formula $\sin(a + b) = \sin(a)\cos(b) + \sin(b)\cos(a)$ to compute the derivative of $\sin$:

\begin{align*}
    \frac{d}{dx}\sin(x)
    &= \lim_{h \rightarrow 0} \frac{\sin(x + h) - \sin(x)}{h}
    = \lim_{h \rightarrow 0} \frac{\sin(x)\cos(h) + \sin(h)\cos(x) - \sin(x)}{h} \\
    &= \lim_{h \rightarrow 0} \frac{\sin(x)(\cos(h) - 1) + \sin(h)\cos(x)}{h} 
    = \lim_{h \rightarrow 0}\Big( \frac{\cos(h) - 1}{h} \Big) \sin(x) + \lim_{h \rightarrow 0}\Big( \frac{\sin(h)}{h} \Big) \cos(x) \\
    &= 0 \cdot \sin(x) + 1 \cdot \cos(x) \\
    &= \cos(x).
\end{align*}

Thus 

\begin{align*}
    \frac{d}{dx} \sin(x) = \cos(x).
\end{align*}

Using the fact that $\cos(x) = \sin(\frac{\pi}{2} - x)$, we can compute the derivative of $\cos(x)$ using the chain rule and our newly acquired expression for the derivative of $\sin$:

\begin{align*}
    \frac{d}{dx} \cos(x) 
    &= \frac{d}{dx} \sin\Big(\frac{\pi}{2} - x\Big) 
    = \cos\Big(\frac{\pi}{2} - x\Big) \frac{d(\frac{\pi}{2} - x)}{dx}
    = -\cos(\frac{\pi}{2} - x) = -\sin(x). 
\end{align*}

Now, we compute the derivative of $\tan = \frac{\sin}{\cos}$. We have

\begin{align*}
    \frac{d}{dx} \tan(x)
    = \frac{d}{dx} \frac{\sin(x)}{\cos(x)} 
    = \frac{\cos(x) \frac{d}{dx} \sin(x) - \sin(x) \frac{d}{dx} \cos(x)}{\cos(x)^2} = \frac{\cos^2(x) + \sin^2(x)}{\cos^2(x)}
\end{align*}

by the quotient rule. We know $\sin^2(x) + \cos^2(x) = 1$ for all $x$, so

\begin{align*}
    \frac{d}{dx} \tan(x) = \frac{1}{\cos^2(x)} = \sec^2(x).
\end{align*}

Recall that $\sec(x) := \frac{1}{\cos(x)}$.

In all, we have

\begin{empheq}[box = \fbox]{align*}
    \frac{d}{dx} \sin(x) &= \cos(x) \\
    \frac{d}{dx} \cos(x) &= -\sin(x) \\
    \frac{d}{dx} \tan(x) &= \sec^2(x)
\end{empheq}

\subsubsection*{Derivatives of inverse functions}

Let $f$ be a function. We will now derive a formula that relates the derivative of $f^{-1}$ to the derivative of $f$. First, notice that since $f \circ f^{-1}$ is the identity $f \circ f^{-1} = I$ defined by $I(y) = y$, we have $\frac{d}{dy}(f \circ f^{-1}) = \frac{dI}{dy} = \frac{d}{dy} y = 1$. (We are using $y$ here because $f^{-1}$ maps outputs of $f$, which we typically denote with $y$, to inputs of $f$).

On the other hand, the chain rule gives us that $\frac{d}{dy}(f \circ f^{-1}) = \frac{df}{df^{-1}} \frac{df^{-1}}{dy}$. 

In all, we have $\frac{df}{df^{-1}} \frac{df^{-1}}{dy} = 1$, and thus 

\begin{empheq}[box = \fbox]{align*}
    \frac{df^{-1}}{dy} &= \frac{1}{\frac{df}{df^{-1}}} = \frac{1}{f' \circ f^{-1}}, \text{ on the domain where $\frac{df}{df^{-1}} \neq 0$} \\
     \frac{df^{-1}}{dy}\Big|_y &= \frac{1}{\frac{df}{dx}}\Big|_{f^{-1}(y)}, \text{ when $\frac{df}{dx}\Big|_{f^{-1}(y)} \neq 0$} \\
    (f^{-1})'(y) &= \frac{1}{f'(f^{-1}(y))}, \text{ when $f'(f^{-1}(y)) \neq 0$}  \\
    (f^{-1})' &= \frac{1}{x} \circ f' \circ f^{-1}, \text{ on the domain where $f' \circ f^{-1}$ is never zero}
\end{empheq}

(In the first and second above equations, the expressions of the form $\frac{1}{g}$ appearing on the right side of the equations denote the function $\frac{1}{g}$ that is defined by $\frac{1}{g}\Big|_x := \frac{1}{g(x)}$ when $g(x) \neq 0$. In the fourth above equation, the $\frac{1}{x}$ on the right side denotes the function defined by $\frac{1}{x}\Big|_p := \frac{1}{x}$ when $p \neq 0$). 

To me, the fourth above statement is the most pleasing. When using it, just be careful to remember that $\frac{df}{df^{-1}} = f' \circ f^{-1}$.

\subsubsection*{Derivatives of inverse trig functions}

\subsection*{Ways to think about derivatives}

[TO DO]

\begin{itemize}
    \item conventional way we already discussed: as rate of instantaneous change/speed, and as slope of tangent line
    \item as densities (not necessarily mass density)
    \item as representing change caused by a particular action, since we often approximate $df \approx \frac{df}{dx} dx$ (esp. when dealing with partial derivatives)
\end{itemize}

\newpage

\section*{The calculus of exponential and logarithmic functions}

In precalculus, you should have learned about the functions $x \mapsto b^x$ and $x \mapsto \log_b(x)$. You may have even learned about the number $e$, and about the natural logarithm $\ln := \log_e$. To properly understand these concepts, especially the concept of $e$, we need the tools of calculus.

\subsection*{Definition of exponential functions}

Let's first review what an exponential function such as $x \mapsto b^x$ really is.

When $x$ is a positive integer, we define $b^x := \underbrace{b \cdot ... \cdot b}_{\text{$x$ times}}$. When $x$ is a negative integer, we define $b^x := \frac{1}{b^{-x}}$. When $x$ is an arbitrary integer, we define $b^{\frac{1}{x}}$ to be such that $f(b) = b^{\frac{1}{x}}$ is the inverse function to $g(b) = b^x$ on the domain $b > 0$; that is, we define $b^{\frac{1}{x}}$ to be such that $f(g(b)) = (b^x)^{\frac{1}{x}} = b = (b^{\frac{1}{x}})^x = g(f(b))$. Sometimes, $b^{\frac{1}{x}}$ is instead written as $\sqrt[x]{b}$.

[see precalc text for more in depth discussion of why these definitions are chosen]

What about when $x$ is an real number, and is thus potentially irrational, i.e., inexpressible as a ratio of two integers? Well, intuitively, one would expect that if $x_{\ell}$ and $x_r$ are rational numbers with $x_{\ell} < x < x_r$, then $b^{x_{\ell}} < b^x < b^{x_r}$. If we could just keep finding rational $x_{\ell}$ and $x_r$ that are closer and closer to $x$, then it would make sense to call the limit approached by $b^{x_{\ell}}$ and $b^{x_r}$ by the name ``$b^x$''.

Fortunately, it is indeed a fact that for every real number $x$ there is a sequence $(x_n)$ of rational numbers converging to $x$. Thus, as suggested above, we \textit{define} $b^x$ to be the limit that is approached by $b^{x_n}$, where the $x_n$ converge to $x$:

\begin{empheq}[box = \fbox]{align*}
    b^x := \lim_{n \rightarrow \infty} b^{x_n}, \text{ where $(x_n)$ is any sequence of rational numbers with $\lim_{n \rightarrow \infty} x_n = x$}
\end{empheq}

For this definition to be valid, we have to show that this limit exists for all $b$ and that, given two distinct sequences $(x_n)$ and $(y_n)$ of rational numbers that converge to $x$, it doesn't matter which sequence we use to compute $b^x$, i.e., $\lim_{n \rightarrow \infty} b^{x_n} = \lim_{n \rightarrow \infty} b^{y_n}$. [See appendix]

\subsubsection*{Properties of exponential functions}

We now discuss some important properties of exponential functions. For all real numbers $b, x, y$, we have:

\begin{itemize}
    \item $b^{x + y} = b^x b^y$
    \item $(b^x)^y = b^{xy}$
    \item When $b > 0$, the function $x \mapsto b^x$ is continuous, one-to-one, and maps to all positive real numbers.
\end{itemize}

We already know from precalculus that the first two properties hold for rational $x$ and $y$. In the appendix, we use the above definition of $b^x$ to show that they hold for real numbers $x$ and $y$. We also show the third property in the appendix.

Note that the third property breaks down when $b < 0$: when $b < 0$, the function $x \mapsto b^x$ is not continuous\footnote{For integer $n, m$, we have that $b^{\frac{n}{m}}$ is positive when $n$ is even and that $b^{\frac{n}{m}}$ is negative when $n$ is odd and $m$ is odd (if $n$ is odd and $m$ is even, then $b^n$ is negative and so $b^{\frac{m}{n}}$ is undefined). Thus $x \mapsto b^x$ oscillates wildly between positive and negative numbers when $b < 0$ in an arbitrary small window of inputs- it cannot be continuous.}, and does not map to every positive real number\footnote{$b^x$ cannot be a positive odd power of $b$ when $b < 0$}.

\subsection*{Definition of logarithms}

$\log_b$ is defined to be the inverse function to $x \mapsto b^x$. So $\log_b$ satisfies $\log_b(b^x)) = x = b^{\log_b(x)}$.

\subsubsection*{$\log_b$ when $b < 0$}

When $b < 0$, the function $\log_b$ is kind of nasty.

[TO DO]

For this reason, we will only consider $\log_b$ when $b > 0$

\subsubsection*{Properties of logarithms}

Once it is shown that the above ``Properties of exponential functions'' hold for real numbers, it is easy to show that the following corresponding properties of logarithms immediately hold. For all real numbers $b, x, y > 0$, we have:

\begin{itemize}
    \item $\log_b(xy) = \log_b(x) + \log_b(y)$
    \item $\log_b(x^y) = y\log_b(x)$
    \item $x \mapsto \log_b(x)$ is continuous, one-to-one, and maps to \textit{all} real numbers.
\end{itemize}

[For intuition that helps with interpreting what these properties are saying, see precalc text.]

Note, we require $b > 0$ so that the third bullet point of ``Properties of exponential functions'' is true, as, if \textit{that} bullet point is true, then the third bullet point of the immediate above must be true too. We require $x, y > 0$ because $x, y$ are elements of the range of $x \mapsto b^x$ (the range of $x \mapsto b^x$ is the positive real numbers).

\subsection*{Changes of base}

\subsubsection*{Change of base for exponential functions}

The \textit{change of base for exponential functions} is the fact that, for any real numbers $a, b$ with $b > 0$,

\begin{align*}
    a^x = b^{\log_b(a^x)} = b^{\log_b(a) x}.
\end{align*}

That is, for any $a, b$ with $b > 0$, we have

\begin{align*}
    a^x = b^{dx}, \text{ where $d = \log_b(a)$}.
\end{align*}

So, it doesn't really matter what base one uses in an exponential function, since any base can be ``converted'' to another base with the above formula.

\subsubsection*{Change of base for logarithms}

We can derive a way to change the base of a logarithm from our knowledge of the change of base for exponential functions. Start with the change of base of exponential functions, and take $\log_b$ of both sides to obtain $\log_b(a^x) = dx$. Let $y = a^x$ to obtain that ${\log_b(y) = d\log_a(y)}$, where $d = \log_b(a)$. Swapping $a$ and $b$ and replacing $y$ with $x$, we have the \textit{change of base for logarithms}:

\begin{align*}
    \log_a(x) = d\log_b(x), \text{ where $d = \log_a(b)$}.
\end{align*}

The change of base for logarithms is often stated as

\begin{align*}
    \log_b(x) = \frac{\log_a(x)}{\log_a(b)}.
\end{align*}

Note that the change of base for logarithms implies that

\begin{align*}
    \log_x(b) = \frac{\log_a(b)}{\log_a(x)} = \frac{1}{\log_b(x)}.
\end{align*}

\subsection*{Derivatives of exponential functions}

Given a real number $b$, let's take the derivative of $b^x$ with respect to $x$.

\begin{align*}
    \frac{d}{dx} b^x = \lim_{h \rightarrow 0} \frac{b^{x + h} - b^x}{h}
    = \lim_{h \rightarrow 0} \frac{b^x (b^h - 1)}{h}
    = \Big( \lim_{h \rightarrow 0} \frac{b^h - 1}{h} \Big) b^x
\end{align*}

Notice that the limit in this last expression can be rewritten:

\begin{align*}
    \lim_{h \rightarrow 0} \frac{b^h - 1}{h} = \lim_{h \rightarrow 0} \frac{b^{0 + h} - b^0}{h} = \Big( \frac{d}{dx} b^x \Big)\Big|_0.
\end{align*}

Thus, the derivative of $b^x$ with respect to $x$ is

\begin{align*}
   \frac{d}{dx} b^x = \Big( \frac{d}{dx} b^x \Big)\Big|_0 b^x.
\end{align*}

That is, the derivative of $b^x$ with respect to $x$ is some constant times $b^x$. In order to obtain a more useful expression for $\frac{d}{dx} b^x$, we must evaluate the expression $\Big( \frac{d}{dx} b^x \Big)\Big|_0$. A natural way to do so is to first consider the $b$ for which\footnote{Does such a $b$ even exist? Does $\Big( \frac{d}{dx} b^x \Big)\Big|_0 = \lim_{h \rightarrow 0} \frac{b^h - 1}{h}$ even converge for all $b$? The answer to both questions is yes, but showing so is quite technical.} we have $\Big( \frac{d}{dx} b^x \Big)\Big|_0 = 1$.

For the sake of having concrete notation, we will \textit{define} $e$ to be the number such that $\Big( \frac{d}{dx} e^x \Big)\Big|_0 = 1$. Then

\begin{align*}
    \frac{d}{dx} e^x = \Big( \frac{d}{dx} e^x \Big)\Big|_0 e^x = 1 \cdot e^x = e^x.
\end{align*}

Now, we use change of base for exponential functions in order to determine $\frac{d}{dx} b^x$ by making use of the fact that we know the derivative of $e^x$. We have

\begin{align*}
    \frac{d}{dx} b^x = \frac{d}{dx} e^{\log_e(b) x} = \log_e(b) e^{\log_e(b) x} = \log_e(b) e^{\log_e(b^x)} = \log_e(b) b^x.
\end{align*}

In all,

\begin{align*}
    \frac{d}{dx} b^x = \log_e(b) b^x.
\end{align*}

In some sense, $e$ is the ``most natural exponent'' because it is the one for which $\frac{d}{dx} e^x = 1 \cdot e^x$. For this reason, the logarithm of base $e$ is called the \textit{natural logarithm}, and is denoted by $\ln$ (for ``logarithmus naturali''). Formally, we define $\ln := \log_e$. So the above is restated as

\begin{align*}
    \boxed
    {
        \frac{d}{dx} b^x = \ln(b) b^x
    }
\end{align*}

\subsubsection*{Alternate expression for $e^x$}

We now make a series of observations that lead us to an alternate expression for $e^x$. To start, recall that we \textit{defined} $e$ to be such that $\Big( \frac{d}{dx} e^x \Big)\Big|_0 = 1$. Also recall that, for any function $f$, the derivative of the inverse function $f^{-1}$ is given by:

\begin{align*}
    \frac{df^{-1}}{dy}\Big|_{f(p)} = \frac{1}{\frac{df}{dx}\Big|_p}.
\end{align*}

Since $x \mapsto e^x$ and $y \mapsto \ln(y)$ are inverse functions, we can substitute $f(x) = e^x$ and $p = 0$ into the above to obtain that

\begin{align*}
    \Big( \frac{d}{dy} \ln(y) \Big)\Big|_1 = 1.
\end{align*}

Computing the derivative of $\ln(x)$ at $x = 1$ explicitly, we have

\begin{align*}
    \lim_{h \rightarrow 0} \frac{\ln(1 + h) - \ln(1)}{h} = \lim_{h \rightarrow 0} \frac{\ln(1 + h)}{h} = \lim_{h \rightarrow 0} \ln((h + 1)^\frac{1}{h}) = 1.
\end{align*}

Interestingly enough, a not yet encountered expression for $e^x$ jumps out at us from this above equation. Apply the function $x \mapsto e^x$ to both sides of the above (using continuity to bring the application of $x \mapsto e^x$ inside the limit) to obtain

\begin{align*}
    \lim_{h \rightarrow 0} (h + 1)^{\frac{1}{h}} = e,
\end{align*}

and then substitute $k := \frac{1}{h}$ to obtain

\begin{align*}
   \lim_{k \rightarrow \infty} \Big( \frac{1}{k} + 1 \Big)^k = e.
\end{align*}

Substituting $n$ in for $k$, we see that we have shown

\begin{align*}
    e &= \lim_{n \rightarrow \infty} \Big(1 + \frac{1}{n} \Big)^n.
\end{align*}

We now use this new expression for $e$ to determine a new expression for $e^x$. We have

\begin{align*}
    e^x = \Big( \lim_{n \rightarrow \infty} \Big(1 + \frac{1}{n} \Big)^n \Big)^x = \lim_{n \rightarrow \infty} \Big(1 + \frac{1}{n}\Big)^{nx}.
\end{align*}

Substitute $p := nx$ to obtain

\begin{align*}
    e^x = \lim_{p \rightarrow \infty} \Big( 1 + \frac{x}{p} \Big)^p.
\end{align*}

Overall, we have shown

\begin{empheq}[box = \fbox]{align*}
    e &= \lim_{n \rightarrow \infty} \Big(1 + \frac{1}{n} \Big)^n \\
    e^x &= \lim_{n \rightarrow \infty} \Big(1 + \frac{x}{n} \Big)^n
\end{empheq}

\subsubsection*{$e$ and compound interest}

Calculus textbooks are overly fond of discussing how to interpret the fact that $e = \lim_{n \rightarrow \infty} \Big(1 + \frac{1}{n} \Big)^n$ in the setting of interest rates, so I include the below for completeness.
    
The argument of the limit, $(1 + \frac{1}{n})^n$, can be interpreted as the factor by which an initial quantity grows when the growth of the quantity occurs in $n$ stages and where the quantity grows by a factor of $1 + \frac{1}{n}$ in each stage. For example, if you put $\$100$ in the bank with a yearly interest rate of $\frac{1}{5} = 20\%$, and let this money sit in the bank for $5$ years, then your $\$100$ would have grown by a factor of $(1 + \frac{1}{5})^5 = (120 \%)^5 = 2.48832 = 248.832\%$ at the end of the $5$ years. So, you would have $\$100 \cdot 2.48832 = \$248.832$ at the end of the $5$ years.

We say that the money \textit{compounds} whenever it grows as a result of applying the interest rate. In the above scenario, the money is compounded $n = 5$ times, once at the end of each year. Taking the limit as $n \rightarrow \infty$ represents using a very small interest rate (an interest rate of $\frac{1}{n}$) infinitely often. Thus, $e$ can be interpreted as the factor by which quantities grow when subject to so-called \textit{continuously compounded} interest.

\subsubsection*{Common pedagogical problems with $e$, $e^x$ and $\ln(x)$}

You should be warned that the usual ways to present $e$, $e^x$ and $\ln(x)$ are all incredibly problematic. In fact, the unproblematic derivation and explanation of $e$, $e^x$ and $\ln(x)$ presented here is so uncommon that I have never read of it in another math textbook, and have only seen it discussed in an online blog by Paramanand Singh.

The problem with these usual ways is that every one of them starts by assuming the truth of one of our ``end results'' (such as $e = \lim_{n \rightarrow \infty} \Big(1 + \frac{1}{n} \Big)^n$ or $e^x = \lim_{n \rightarrow \infty} \Big(1 + \frac{x}{n} \Big)^n$, or even facts we haven't learned of yet, like ``$e = \sum_{n = 0}^\infty \frac{1}{n!}$'', ``$e^x = \sum_{n = 0}^\infty \frac{x^n}{n!}$'', and ``$\ln(x) = \int_1^x \frac{1}{x} dx$'') and then uses said ``end result'' as a starting point from which to establish the properties of $e$, $e^x$ and $\ln(x)$. This is unintuitive and unnatural- who could reasonably come up with the idea to use one of these ``end results'' as a starting point without doing a ridiculous amount of prior investigation? Well-explained math is math that feels at least somewhat plausible to discover, and starting with one of the mentioned ``end results'' is not of this spirit.

\subsection*{Derivatives of logarithms}

\section*{Analytical geometry}

\begin{itemize}
    \item Increasingness, decreasingness, local/global extrema
    \begin{itemize}
        \item Extreme value theorem: if an extremum of $f$ occurs at $x$, then $\frac{df}{dx}\Big|_x = 0$.
        \begin{itemize}
            \item The converse of extreme value theorem is not true: it is not necessarily true that if $\frac{df}{dx}\Big|_x = 0$, then $x$ is an extreme value of $f$.
        \end{itemize}
    \end{itemize}
    \item Concavity, inflection points
    \item Horizontal and vertical asymptotes
\end{itemize}

\section*{Misc.}

\begin{itemize}
    \item Mean value theorem
    \begin{itemize}
        \item Isn't ``misc'' if you're proving calculus, but is ``misc'' if you're using calculus.
    \end{itemize}
    \item L'Hopital's rule
\end{itemize}

\newpage

\part*{Integral calculus}

\section*{Riemann sums and definite integrals}

\subsection*{Riemann sums}

Given the derivative $\frac{df}{dx}$ of some function $f$, we can approximate the change in $f$ from $x = a$ to $x = b$ as follows. First, we break up the interval $[a, b]$ into many intervals:

\begin{align*}
    [x_1, x_2] = [a, x_2], [x_2, x_3], ..., [x_{n - 1}, x_n] = [x_{n - 1}, b], \text{ where $x_{i + 1} > x_i$}.
\end{align*}

Next, we approximate $\frac{df}{dx}$ as a piecewise function that is constant on each piece. For a particular ``piece'' $[x_i, x_{i + 1}]$, we pick one of the values that $\frac{df}{dx}$ takes on within this interval, and then define our piecewise approximation to be equal to this value when evaluated on any input inside the same interval.

Lastly, we apply the formula $(\text{change in output}) = (\text{rate of change}) \cdot (\text{change in input})$, which is true for constant rates of change, on each piece, and sum up the changes in output of all the pieces to obtain an approximation of the total change in $f$ from $x = a$ to $x = b$. The approximation gets better as we use more pieces. 

Symbolically, all the previous steps combine to tell us that the change in $f$ from $x = a$ to $x = b$ is approximately:
 
\begin{align*}
    f(b) - f(a) \approx \sum_{i = 1}^n \frac{df}{dx}\Big|_{x = s_i} (\Delta x)_i, \text{ where $\Delta x)_i = x_{i + 1} - x_i$},
\end{align*}

and where we choose $s_i$ in one of the following ways:

\begin{align*}
 s_i &= x_i \text{ for a \textit{left Riemann sum}} \\
 s_i &= x_i + \frac{(\Delta x_i)}{2} \text{ for a \textit{midpoint Riemann sum}} \\
 s_i &= x_{i + 1} \text{ for a \textit{right Riemann sum}}.
\end{align*}

The choice of $s_i$ determines which value our piecewise approximation takes on in each piece; for example, if a left Riemann sum is chosen, then the piecewise approximation takes on the ``leftmost'' value of $f$ within that piece.

We have used the words ``Riemann sum'' in the above definition of $s_i$, but not explained what ``Riemann sum'' means. What is a Riemann sum? A \textit{Riemann sum of a function $g$ from $a$ to $b$} is a sum of the form

\begin{align*}
    \sum_{i = 1}^n g(s_i) (\Delta x)_i, \text{ where $(\Delta x)_i = x_{i + 1} - x_i$},
\end{align*}

where the intervals $[x_i, x_{i + 1}]$ are chosen in the same way as above (in particular, we must have $x_1 = a$ and $x_n = b$), and where the $s_i$ are chosen in one of the ways described above.

So, the above sum involving $\frac{df}{dx}\Big|_{x = s_i}$ is a Riemann sum of $\frac{df}{dx}$ from $a$ to $b$.

\subsubsection*{Riemann sums and area}

If one has a function $g$ and draws a graph of $g$ vs. $x$, they can notice that $g(s_i) (\Delta x)_i$ is the width of the rectangle with height $g(s_i)$ and width $(\Delta x)_i$. So, a Riemann sum of $g$ from $a$ to $b$ approximates the area under the graph of $g$ that is above the $y$-axis and between the vertical lines $x = a$ and $x = b$.

\subsection*{The definite integral}

We define the \textit{definite integral from $a$ to $b$} of a function $g$ to be the following limit of a Riemann sum:

\begin{align*}
    \int_a^b g(x) dx := \lim_{\max((\Delta x)_i) \rightarrow 0} \sum_{i = 1}^n g(s_i) (\Delta x)_i, \text{ where $s_i$ is any of the above}.
\end{align*}

In the limit, the maximum input interval $\max((\Delta x)_i)$ approaches $0$, so all other input intervals are forced to approach $0$ as well. Thus, the above limit corresponds to approximating the change in $g$ when $g$ is approximated as a piecewise function of ``infinitely many'' pieces.

Since a Riemann sum of $\frac{df}{dx}$ from $a$ to $b$ approximates the change in $f$ over this input interval,

\begin{align*}
     f(b) - f(a) \approx \sum_{i = 1}^n \frac{df}{dx}\Big|_{x = s_i} (\Delta x)_i,
\end{align*}

it stands to reason that the definite integral of $\frac{df}{dx}$ from $a$ to $b$, being an ``infinitely accurate Riemann sum'', will be equal to this change:

\begin{align*}
    f(b) - f(a) = \int_a^b \frac{df}{dx}\Big|_x dx.
\end{align*}

This is indeed true.

\subsubsection*{The definite integral and area}

In the previous section, we noted that ``a Riemann sum of $g$ from $a$ to $b$ approximates the area under the graph of $g$ that is above the $y$-axis and between the vertical lines $x = a$ and $x = b$''. Since an integral is intuitively an ``infinitely accurate Riemann sum'', the exact area under the graph of $g$ from $a$ to $b$ is $\int_a^b g(x) dx$.

\section*{Antiderivatives and the fundamental theorem of calculus}

Our investigation of Riemann sums and definite integrals showed that we can compute the change in a function $f$ over an input interval $x = a$ to $x = b$ as

\begin{align*}
    f(b) - f(a) = \int_a^b \frac{df}{dx}\Big|_x dx.
\end{align*}

Since any continuous function is the derivative of some other continuous function, we can rewrite the above by interpreting $\frac{df}{dx}$ to be an arbitrary continuous function $g$:

\begin{align*}
    ? = \int_a^b g(x) dx
\end{align*}

We used a question mark in the above because it is somewhat unclear how to convert the previous left side of the equation, $f(b) - f(a)$, into an expression that involves $g$ rather than $f$.

In order to figure out what $?$ is, notice that in the equation $f(b) - f(a) = \int_a^b \frac{df}{dx}\Big|_x dx$, the function on the right side, $\frac{df}{dx}$, is the derivative of the function on the left side, $f$. So it stands to reason that in the above equation, the function $g$ on the right side is the derivative of whatever function is involved in the left side. Therefore, we will guess that

\begin{align*}
    G(b) - G(a) = \int_a^b g(x) dx , \text{ where $\frac{dG}{dx} = g$}.
\end{align*}

In order to prove that this guess is correct, we must think more about the function $G$.

In general, any function $H$ that satisfies $\frac{dH}{dx} = g$ is said to be an \textit{antiderivative of $g$}. (Thus, the $G$ above is an antiderivative of $g$). Observe that there are many antiderivatives of any function, since, if $H$ is an antiderivative of $g$ and $c$ is a constant, then $H + c$ must be an antiderivative of $g$ as well\footnote{$\frac{d}{dx}(H + c) = \frac{dH}{dx} + 0 = \frac{dH}{dx} = g$}. 

In fact, one can show that \textit{any} two antiderivatives of a function must differ by a constant\footnote{Suppose $F$ and $G$ are both antiderivatives of $g$. Then $\frac{d}{dx}F = \frac{d}{dx}G$, so $\frac{d}{dx}F - \frac{d}{dx}G = 0$. Using the linearity of the derivative, we have $\frac{d}{dx}(F - G) = 0$. It follows from the mean value theorem that if a function's derivative is zero for all inputs, then the function must be a constant function. Applying this fact to the function $F - G$, we see that $F - G$ must be a constant function. That is, $F$ and $G$ differ by a constant.}. This is very important- it means that if you've found one antiderivative of a function, you've really found all its antiderivatives: the collection of all antiderivatives is equal to the collection of functions obtained by adding constants to the one antiderivative you found.

Now, we can justify our above guess; we can justify why the old left side $f(b) - f(a)$ is equal to the new left side $G(b) - G(a)$. The justification is as follows. Since $f$ and $G$ are antiderivatives of $\frac{df}{dx} = g$, they differ by a constant: for each $x$, we have $f(x) = g(x) + d$ for some constant $d$. This implies that $f(b) - f(a) = (G(b) + d) - (G(a) + d)) = G(b) - G(a)$, as we claimed.

We now restate the equation above, with the only change being that we use the letters $f$ and $F$ instead of $g$ and $G$. This equation is called the \textit{the second part of the fundamental theorem of calculus}. We will abbreviate it as \textit{FTC 2}.

\begin{align*}
    \int_a^b f(x) dx = F(b) - F(a), \text{ where $\frac{dF}{dx} = f$}.
\end{align*}

If $x$ is substituted for $b$, FTC 2 can be written as

\begin{align*}
    F(x) = \int_a^x f(x) dx + F(a), \text{ where $\frac{dF}{dx} = f$}.
\end{align*}

This shows that any antiderivative can be written as a definite integral plus a constant. For this reason, the taking of an antiderivative is notated with an integral symbol without limits of integration:

\begin{align*}
    \text{``$F(x) = \int f(x) dx$'' means ``$F$ is an antiderivative of $f$''}.
\end{align*}

Such integrals without limits are called \textit{indefinite}. With this new notation, FTC 2 can be written as

\begin{align*}
    \int_a^b f(x) dx = F(b) - F(a), \text{ where $F(x) = \int f(x) dx$}.
\end{align*}

\textit{The first part of the fundamental theorem of calculus} follows as a logical consequence of the second part. From above, we have

\begin{align*}
    F(x) = \int_a^x f(x) dx + F(a).
\end{align*}

Take the derivative of both sides with respect to $x$ to obtain \textit{the first part of the fundamental theorem of calculus}, which we abbreviate as \textit{FTC 1}:

\begin{align*}
    f(x) = \frac{d}{dx} \int_a^x f(x).
\end{align*}

We restate FTC 2 and FTC 1 for convenience:

\begin{empheq}[box = \fbox]{align*}
    \int_a^b f(x) dx &= F(b) - F(a), \text{ where $F(x) = \int f(x) dx$} \\
    \frac{d}{dx} \int_a^x f(x) &= f(x)
\end{empheq}

\vspace{.5cm}

FTC 2 and FTC 1 formalize the sense in which antiderivatives and definite integrals are related. FTC 2 says that definite integrals can be computed by evaluating antiderivatives. FTC 1 says that the function $x \mapsto \int_a^x f(x) dx$, which involves a definite integral, is an antiderivative of $f$.

Note that the previous sentence implies:

\begin{align*}
    \boxed
    {
        \text{Every continuous function has an antiderivative.}
    }
\end{align*}

Contrastingly, recall that it is \textit{not} the case that every continuous function has a derivative.

\subsubsection*{Why FTC 2 before FTC 1?}

We've proved FTC 2 implies FTC 1. It's also possible to prove FTC 1 implies FTC 2. 

In my opinion, FTC 2 is more intuitive than FTC 1. FTC 1 says ``the rate of change of the `accumulation' of $f$ is equal to $f$ itself'', which seems a bit complicated for someone to intuit. FTC 2, which says that adding up many ``infinitesimal'' changes gives an overall change, seems to be a much easier discovery. Since FTC 1 is easily seen to follow from FTC 2, I think that treating FTC 2 as the fundamental principle and FTC 1 as a corollary is the way to go.

\subsection*{Integral notation}

Before we proceed further, we should define some conventions for notating integrals. So far, the only conventions we've established are that that the definite integral of a function $f$ from $a$ to $b$ is written as $\int_a^b f(x) dx$ and that the evaluation at $x$ of an antiderivative of a function $f$ is written as $\int f(x) dx$. 

We now lay out new conventions analogous to prime notation\footnote{The notations $\int f$, $\int_a^b f$, and $f'$ are analogous because they are concern functions, not functions evaluated on inputs.} for derivatives:

\begin{align*}
    \int f := \text{an antiderivative of $f$}, &\quad \int_a^b f := \text{the definite integral of $f$ from $a$ to $b$}.
\end{align*}

With these new conventions, we can restate the already established integral notation more clearly:

\begin{align*}
    \int f(x) dx := \Big(\int f\Big)\Big|_x, &\quad \int_a^b f(x) dx := \int_a^b f.
\end{align*}

We now slightly amend the definition of $\int f(x) dx$:

\begin{align*}
    \int f(x) dx := 
    \begin{cases}
        \int f \\
        \Big(\int f\Big)\Big|_x
    \end{cases},
    \text{ where the choice is determined from context}.
\end{align*}

Note that this definition is analogous to the definition of $\frac{df}{dx}$ as being either $f'$ or $f'(x)$.

\vspace{.5cm}

Lastly, we define the vocabulary word \textit{integrand}. The integrand of an integral is just the argument of that integral. So, the integrand of $\int f$ is $f$ and the integrand of $\int f(x) dx$ is $f(x)$.

\section*{Integration formulas}

In this section, we derive several integration formulas. We often do so by starting with a differentiation formula, taking the antiderivative of both sides, and interpreting some derivative that appears in the resulting expression to be ``just a regular function''. Such interpretations are valid because FTC 1 tells us that every continuous function has an antiderivative. Because integral formulas make use of this interpretation in their derivations, they all require that certain derivatives are continuous; i.e., they all require that certain functions are ``continuously differentiable''. 

In spite of the above note about ``continuous differentibility'', I will not be a stickler about stating the conditions that must be satisfied for a fact about integrals to be applicable, just as was the case when deriving derivative formulas. I will make note of conditions when doing derivations, but will not restate them in final ``boxed'' formulas. Conditions for integral formulas are in general less self-evident than those for derivative formulas, but you can still determine good guesses as to what the conditions are by starting with the corresponding derivative formula and integrating both sides.

\subsection*{Change of variables theorem}

First, we will derive the fact for integrals that corresponds to the chain rule for derivatives. Recall that the chain rule can be stated as

\begin{align*}
    (g \circ f)' = (g' \circ f) \circ f'.
\end{align*}

Integrate both sides to obtain

\begin{align*}
    g \circ f = \int (g' \circ f) \circ f'.
\end{align*}

Now, we will think of $g'$ as being ``just a regular function''. To formalize this, substitute $h := g'$. This implies\footnote{We need to justify that $h$ has an antiderivative here. In order for this to be guaranteed, we actually needed to assume at the beginning that $g$ is \textit{continuously differentiable}, i.e., that $g'$ is continuous. This is a pretty technical detail, so we don't mention it outside this footnote.} $g = \int h$, and we have

\begin{align*}
    \Big( \int h \Big) \circ f = \int (h \circ f) f'.
\end{align*}

Now, substitute the letter $g$ in for the letter $h$, and ``flip'' the equation around to obtain our primary result.

\begin{align*}
    \int (g \circ f) f' = \Big(\int g \Big) \circ f.
\end{align*}

Using Leibniz notation, the primary result can be restated as
        
\begin{align*}
    \int (g \circ f) \frac{df}{dx} dx = \Big(\int g \Big) \circ f.
\end{align*}

We now \textit{define} the following notation,

\begin{align*}
    \int g \spc df &:= \Big( \int g \Big) \circ f,
\end{align*}

for a similar reason to the one that motivated us to define $\frac{dg}{df} := f' \circ g$. That reason is: one way to evaluate $\int g \spc df = \Big( \int g \Big) \circ f$ at an input $x$ is to first compute the integral $\int g(f) df$, making sure to use the letter $f$ when doing so, and to then substitute $f(x)$ in for $f$:

\begin{align*}
    \Big(\int g \spc df\Big)\Big|_x = \Big( \Big( \int g \Big) \circ f\Big)\Big|_x = \Big(\int g(f) \spc df\Big)\Big|_{f \rightarrow f(x)}.
\end{align*}

With this new notation, the above ``primary result'' restates as the following theorem.

\begin{empheq}[box = \fbox]{align*}
    \int (g \circ f) \frac{df}{dx} dx = \int g \spc df, 
    \text{ where } \int g \spc df := \Big( \int g \spc dx \Big) \circ f = \Big( \int g \Big) \circ f
\end{empheq}

This theorem makes the idea of ``canceling differentials'' within integrals rigorous, since it appears as if the $df$ in the ``denominator'' of the integrand on the left side is canceled by the $df$ that is the placeholder of the left side's integrand\footnote{A quicker proof, which you might discover if you suspected the primary result to be true is as follows. First, notice that the chain rule implies ${\frac{d}{dx} \Big( \Big( \int g \Big) \circ f \Big) = (g \circ f)\frac{df}{dx}}$. Then integrate both sides.}.

Please note that the definition $\int g \spc df := \Big(\int g \Big) \circ f$ is unconventional. However, as was the case with the definition $\frac{dg}{df} := g' \circ f$, this definition is often used implicitly by physicists.

Since we've defined $\int g \spc df$, we should also define $\int g(f) df$. The definition is pretty simple; we define $\int g(f) df := \int g \spc df$.

The theorem is often stated with the substitutions $g = f$ and $f = u$:

\begin{empheq}[box = \fbox]{align*}
    \int (f \circ u) \frac{du}{dx} dx = \int f \spc du,
    \text{ where } \int f \spc du := \Big( \int f \spc dx \Big) \circ u = \Big( \int f \Big) \circ u \\
    \int f(u(x)) \frac{du}{dx} dx = \Big(\int f(u) du\Big)\Big|_x,
    \text{ where } \int f(u) du := \int f \spc du.
\end{empheq}

\subsubsection*{Integration by substitution}

We now present the method that most people use in practice to apply the change of variables theorem. Suppose we have encountered the integral from the left side of the change of variables theorem, $\int (f \circ u) \frac{du}{dx} dx$.

You are actually probably more likely to encounter the equivalent integral

\begin{align*}
    \int f(u(x)) \frac{du}{dx} dx.
\end{align*}

In any case, if we treat the derivative $\frac{du}{dx}$ as an actual fraction, then we have ``$\frac{du}{dx} dx = du$'' and thus ``$dx = \frac{1}{du/dx} du$''. Substituting this expression for $dx$ into the above integral, we obtain

\begin{align*}
    \text{``}\int f(u(x)) \frac{du}{dx} \underbrace{\frac{1}{du/dx} du}_{dx} = \int f(u(x)) du \text{''}.
\end{align*}

We've used quotes because the above expressions are mnemonics, and not truly mathematically valid. 

One now ``magically disappears'' the $x$ within $f(u(x))$ (there is no real justification for this- it is a mnemonic after all), to obtain $f(u)$, and thus the above integral becomes $\int f(u) du$. If we also ``magically'' remember to evaluate the integral at $x$ at the end, it becomes

\begin{align*}
    \Big(\int f(u) du\Big)\Big|_x,
\end{align*}

which is the right side of the change of variables theorem.

Thus, using the mnemonic of treating $\frac{du}{dx}$ as an actual fraction provides a way to remember the change of variables formula, 

\begin{align*}
    \int f(u(x)) \frac{du}{dx} dx = \Big( \int f \spc du \Big)\Big|_x,
\end{align*}

since multiplying the integrand of the left side by the mnemonic expression ``$\frac{1}{du/dx} du$'' produces the right side of the theorem. Utilizing this mnemonic is called \textit{integration by substitution}, or ``$u$-substitution''.

\subsubsection*{Example of integration by substitution}

We give an example of how to use the change of variables in (1) a formal sense and (2) by using the mnemonic described above. In both cases, we will compute

\begin{align*}
    \int \frac{\ln(x)}{x} dx.
\end{align*}


\begin{enumerate}
    \item Here's how to use the change of variables theorem in a ``strictly correct'' way. To compute $\int \frac{\ln(x)}{x} dx$, we notice that the integrand is of the form $f(u(x)) \frac{du(x)}{dx}$, where $f(u) = u$, $u(x) = \ln(x)$, and $\frac{du}{dx} = \frac{1}{x}$. Directly applying the change of variables theorem, we have 
    
    \begin{align*}
        \int \frac{\ln(x)}{x} dx = \int f(u(x)) \frac{du(x)}{dx} dx = \int f(u) du = \Big(\Big(\int f\Big) \circ u\Big)\Big|_x.
    \end{align*}
    
    Since the letter $u$ is already in use, we will write $\int f$ as $\int f = \int f(v) dv$. We have:
    
    \begin{align*}
        \Big(\int f\Big) \circ u &= \Big(\int f(v) dv \Big) \circ u = \Big(\int v \spc dv \Big) \circ u = \Big( v \mapsto \Big( \frac{1}{2}v^2 + c \Big) \Big) \circ u \\
        &= \Big( v \mapsto \Big( \frac{1}{2}v^2 + c \Big) \Big) \circ u = \Big( v \mapsto \Big( \frac{1}{2}u(v)^2 + c \Big) \Big)
        =  \Big( v \mapsto \Big( \frac{1}{2}\ln^2(v) + c \Big) \Big).
    \end{align*}
    
    Evaluating this function at $v = x$, we have 
    
    \begin{align*}
        \int \frac{\ln(x)}{x} dx = \frac{1}{2} \ln^2(x) + c.
    \end{align*}
    
    \item Here is an example of how to use the mnemonic. If we want to compute $\int \frac{\ln(x)}{x} dx$, then we set $u(x) = \ln(x)$, compute $\frac{du}{dx} = \frac{1}{x}$, and then see ``$dx = x \spc du$''. Substituting this expression for $dx$ into the integral, we have
    
    \begin{align*}
        \int \frac{\ln(x)}{x} dx = \int \frac{u(x)}{x} x \spc du = \int u \spc du = \frac{1}{2} u^2 + c = \frac{1}{2}\ln^2(x) + c.
    \end{align*}
\end{enumerate}

\subsection*{Separation of variables}

One important application of the change of variables theorem is the solving of so-called \textit{separable differential equations}, which are equations of the form 

\begin{align*}
    \frac{df}{dx}\Big|_x = f(x) g(f(x)).
\end{align*}

(In general, a \textit{differential equation} is an equation that involves a function and one or more of its derivatives).

To solve the above equation, we will apply the change of variables theorem and ``cancel differentials''.

Rephrasing the original equation, we have

\begin{align*}
    \frac{1}{g(f(x))} \frac{df}{dx}\Big|_x = f(x) \text{ for all $x$ with $g(f(x)) \neq 0$}
\end{align*}

Integrate both sides to obtain

\begin{align*}
    \int \frac{1}{g(f(x))} \frac{df}{dx}\Big|_x dx = \int f(x) dx \text{ for all $x$ with $g(f(x)) \neq 0$}.
\end{align*}
 
Now use the change of variables theorem to ``cancel the $dx$'s on the left side'':

\begin{align*}
    \boxed
    {
        \int \frac{1}{g(f)} df = \int f(x) dx \text{ for all $f$ with $g(f) \neq 0$}.
    }
\end{align*}

In practice, we (attempt to) solve the separable differential equation by explicitly computing the above integrals and then using algebra to solve the above equation for $f$.

The above integral equation can be remembered by the mnemonic of starting with the original separable differential equation

\begin{align*}
    \frac{df}{dx}\Big|_x = f(x) g(f(x)),
\end{align*}

and then doing algebra to ``put the $f$'s and $df$'s on one side and put the $x$'s and $dx$'s on the other side''. We divide both sides by $g(f(x))$ (since $g(f(x))$, when loosely interpreted as ``$g(f)$'', involves $f$) to get the $f$'s and $df$'s on the left side, and ``multiply both sides by $dx$'' to get the $x$'s on the right side: 

\begin{align*}
    \frac{df}{g(f(x))} = f(x) dx.
\end{align*}

Now we magically disappear the $x$ on the left side and ``integrate both sides'' of the above mnemonic expression to obtain

\begin{align*}
    \int \frac{1}{g(f)} df = \int f(x) dx,
\end{align*}

exactly as before.

\subsection*{Integration by parts}

\begin{itemize}
    \item Is the ``reverse product rule''.
    \item $(fg)' = f'g + g'f$. Integrate both sides to obtain $fg = \int f'g + g'f dx = \int f'g dx + \int g'f dx$. Now subtract one of the integrals on the right side to obtain either
    
    \begin{align*}
        \int f'g \spc dx = fg - \int fg' \spc dx
    \end{align*}
    
    or
    
    \begin{align*}
        \int fg' \spc dx = fg - \int f'g \spc dx.
    \end{align*}
    
    It doesn't matter which of the above equations you use, as swapping $f$ and $g$ in one of the equations yields the other. We will consider the second equation,
    
    \begin{align*}
        \int fg' \spc dx = fg - \int f'g \spc dx.
    \end{align*}
    
    Substitute $h = g'$, so $g = \int h dx$. Thus
    
    \begin{align*}
        \int fh \spc dx = fh - \int f'H \spc dx, \text{ where } H = \int h \spc dx.
    \end{align*}
    
    Rewriting the above with the letters $f, g$, and $G$, we have
    
    \begin{align*}
        \boxed
        {
            \int fg \spc dx = fg - \int f'G \spc dx, \text{ where } G = \int g \spc dx
        }
    \end{align*}
    
    When using the above formula, pick $f$ to be a function whose derivative is computable, and pick $g$ to be a function whose integral is computable.
    
    [insert spaces in integrals]
    
    
    \item I advise that you do not use the mnemonic involving $u, v, du$, and $dv$. It's more confusing to use the mnemonic than to rederive the integration by parts formula, in my opinion. 
\end{itemize}

\newpage

\part*{Appendix}

\subsection*{The power rule for real number exponents}

Unfortunately, this proof requires knowledge of the calculus of exponential and logarithmic functions, which one does not know these concepts when they first encounter the power rule.

By the change of base for exponential functions, we have $x^c = e^{c\ln(x)}$. Thus

\begin{align*}
    \frac{d}{dx} x^c = \frac{d}{dx} e^{c\ln(x)} = e^{c\ln(x)} \cdot \frac{c}{x} = x^c \cdot \frac{c}{x} = cx^{c - 1}.
\end{align*}

%\subsubsection*{Approach 2: prove and use the generalized binomial theorem}

%We will show that a generalized version of the binomial theorem holds; we will show that for any real numbers $a, b, c$, we have

%\begin{align*}
%    (a + b)^c = \sum_{k = 0}^\infty {}_c C_k a^{c - k} b^k \text{ when $|b| < |a|$}.
%\end{align*}

%Once we know this fact, we can follow a similar argument as was used to show that $\frac{d}{dx}x^n = nx^{n - 1}$ for integer $n$. We compute the derivative of $x^c$ as

%\begin{align*}
%    \frac{d}{dx} x^c = \lim_{h \rightarrow 0} \frac{(x + h)^c - x^c}{h}.
%\end{align*}

%Then, we use $a = x$ and $b = h$ in the above generalized binomial theorem to expand $(x + h)^c$. Note the restriction $|b| = |h| < |x| = |a|$ for the generalized binomial theorem does not hinder us, since, as $h \rightarrow 0$, we can ignore the values of $h$ for which the restriction is not true. Thus we have\footnote{In the below we use various theorems about infinite sums. The results of these theorems are intuitive (i.e. they are analogs of theorems that hold for regular finite sums), but they still do need to be proved for the argument to be made perfectly rigorous.}

%\begin{align*}
%    \lim_{h \rightarrow 0} \frac{\sum_{k = 0}^\infty ({}_c C_k x^{c - k} h^k)  - x^c}{h}
%    &= \lim_{h \rightarrow 0} \frac{\sum_{k = 0}^\infty ({}_c C_k x^{c - k} h^k)  - x^c}{h}
%    = \lim_{h \rightarrow 0} \frac{x^c + cx^{c - 1}h + \sum_{k = 2}^\infty ({}_c C_k x^{c - k} h^k)  - x^c}{h} \\
%    &= cx^{c - 1} + \lim_{h \rightarrow 0} \sum_{k = 2}^\infty ({}_c C_k x^{c - k} h^{k - 1}) 
%    = cx^{c - 1} + \sum_{k = 2}^\infty ({}_c C_k x^{c - k} \lim_{h \rightarrow 0} (h^{k - 1}))
%    = cx^{c - 1}.
%\end{align*}

%So, we get $\frac{d}{dx} x^c = cx^{c - 1}$ \textit{if} the generalized binomial theorem is true. We now prove the generalized binomial theorem by showing that the infinite series of the generalized binomial theorem is the Taylor series of the function $f_{a, c}$ defined by $f_{a,c}(b) := (a + b)^c$. 

%Using the power rule for integer exponents, we have

%\textbf{WE MUST ASSUME $c$ is an integer to use the power rule, which blocks us from obtaining the desired deriative.}

%\begin{align*}
%    \frac{df_{a,c}}{db}\Big|_b = c(c - 1) ... (c - k + 1)(a + b)^{c - k} = ({}_c C_k k!) (a + b)^{c - k},
%\end{align*}

%so $\frac{df_{a,c}}{db}\Big|_0 = ({}_c C_k k!) a^{c - k}$, and thus the Taylor series for $f_{a,c}$ centered at $0$ is

%\begin{align*}
%    T(b) = \sum_{k = 0}^\infty \frac{1}{k!} \frac{df_{a,c}}{db}\Big|_0 b^k = \sum_{k = 0}^\infty \frac{1}{k!} ({}_c C_k k!) a^{c - k} b^k = \sum_{k = 0}^\infty {}_c C_k a^{c - k} b^k.
%\end{align*}

%Letting $T_k$ denote the $k$th term of the Taylor series, we have $\lim_{k \rightarrow \infty} \Big| \frac{T_{k + 1}}{T_k} \Big| = \lim_{k \rightarrow \infty} \Big| \frac{n - k}{k + 1}a^{-1}b \Big|$. The ratio test states that if $a, b$ are such that $\lim_{k \rightarrow \infty} \Big| \frac{T_{k + 1}}{T_k} \Big| < 1$, then we have $f_{a,c}(b) = T(b)$. Using the previous expression for $\lim_{k \rightarrow \infty} \Big| \frac{T_{k + 1}}{T_k} \Big| < 1$ shows that we have $f_{a,c}(b) = T(b)$ when $|b| < |a|$.

\subsection*{Summary of conventions regarding Leibniz notation}

Suppose you are doing some calculations in which you have force $F$ as a function of position $x$ and position $x$ as a function of time $t$. (Don't worry if you don't know what ``force'' actually is). So, formally, you have a function $F_x$ that maps position to force and a function $x_t$ that maps time to position. From these functions, we can obtain a function $F_t$ that maps time to force, defined by $F_t(t) := F_x(x_t(t))$, i.e. $F_t = F_x \circ x_t$.

You might find that not thinking of force as a function of any particular variable, but as ``just force'', simplifies your thinking and writing. For this reason, you might write simply ``$F$'' instead of ``$F_x$'' or ``$F_t$'' as you do calculations.

After arriving at a final calculation involving $F$- maybe your final calculation is something like $2 F^3 + F^2$- you can choose to think of $F$ as a function of position or as a function of time, and substitute either $F_x$ or $F_t$ in for $F$. So, you would have $2 F^3 + F^2 = 2 F_x^3 + F_x^2 = 2 F_t^3 + F_t^2$.

\vspace{.25cm}

Let's now consider the situation from a more general perspective. Just as occurred in the above example, every symbol $S$ representing a physical quantity is typically associated with a ``preferred symbol'' $T$, in the sense that we prefer to think of the physical quantity represented by $S$ as depending on the physical quantity represented by $T$ rather than as depending on some other physical quantity. In the above example, the preferred symbol of $F$ would be $x$, since we started with the functions $F_x$ and $x_t$. $F$'s preferred symbol is \textit{not} $t$, because we did not start with the function $F_t$, and instead had to deduce it from $F_x$ and $x_t$.

In general, let's use $\overline{S}$ to denote the preferred symbol of an arbitrary symbol $S$, and let's use $S_T$ to denote the function that maps the physical quantity represented by $T$ to the physical quantity denoted by $S$. Note that in analogy to the fact $F_t = F_x \circ x_t$, we have $S_T = S_{\overline{S}} \circ \overline{S}_T$. [We'll also establish the convention that for any symbol $S_S$ is equal to the identity function for any symbol $S$.] 

One last notion we'll need is that of a symbol being an ``eventual preferred letter''. We will say that a symbol $T$ is an \textit{eventual preferred letter} of a symbol $S$ if $T$ is one of the symbols $\overline{S}, \overline{\overline{S}}, \overline{\overline{\overline{S}}}, \overline{\overline{\overline{\overline{S}}}}, ...,$ and so on.

Now, remember how we conflated $F$ with $F_x$ previously? Analogously, when it is clear what a symbol $S$'s preferred symbol $\overline{S}$ is, it makes some sense to conflate the symbol $S$ with the function $S_{\overline{S}}$. Once this conflation has been established, then it is sensible to define 

\begin{align*}
    \frac{dS}{dT} :=
    \begin{cases}
        \frac{dS_T}{dT} & \text{$T$ is an eventual preferred letter of $S$} \\
        0 & \text{$T$ is not an eventual preferred letter of $S$}
    \end{cases},
\end{align*}

This definition formalizes practice of using the symbol in the ``denominator'' of the derivative to determine what function is being differentiated.

To spell things out, this definition has the following consequences:

\begin{align*}
    \frac{dS}{d\overline{S}} &:= \frac{dS_{\overline{S}}}{d\overline{S}} = {S_{\overline{S}}}' \\
    \frac{dS}{dT} &:= \frac{dS_T}{dT} = \frac{d(S_{\overline{S}} \circ \overline{S}_T)}{dT} = 
    (S_{\overline{S}} \circ \overline{S}_T)' \text{ when $T$ is an eventual preferred letter of $S$ with $T \neq \overline{S}$}.
\end{align*}

Specifically, in the example, we have

\begin{align*}
    \frac{dF}{dx} &= \frac{dF_x}{dx} = F_x' \\
    \frac{dF}{dt} &= \frac{dF_t}{dt} = \frac{d(F_x \circ x_t)}{dt} = (F_x \circ x_t)'.
\end{align*}

\vspace{.5cm}

[Need this before stating chain rule. Suppose $\Phi$ is function addition, function multiplication, or function composition. (So, $\Phi(S, T)$ is either equal to $S + T$, or $ST$, or $S \circ T$ (assuming $S$ and $T$ are compo sable)). If $T$ is an eventual preferred letter of $S$, then $\Phi(S, T)$ is interpreted to mean $\Phi(S_{\overline{T}}, T)$ and to have preferred letter $\overline{T}$.]
\begin{itemize}
    \item Example: If $\overline{g} = f$ and $\overline{f} = x$ then $g_x = g_f \circ f_x = g \circ f$. Therefore $gf$ is interpreted to be $g_x f = (g  \circ f) f$, and, since $\overline{\frac{df}{dx}} = x$, $g \frac{df}{dx}$ is interpreted to mean $(g \circ f) \frac{df}{dx}$.
\end{itemize}

\begin{mdframed}
    If $f$ is the preferred letter of $g$, and $x$ is the preferred letter of $f$, then 
        
    \begin{align*}
        \frac{dg}{dx} = \frac{dg}{df} \frac{df}{dx}.
    \end{align*}
    
    [$\frac{dg}{df}$ is interpreted as $\frac{dg_x}{dx} = g' \circ f$ due to above rule involving $\Phi$]
\end{mdframed}

For comparison, the nicest possible way to state the chain rule without the notion of ``preferred letters'' is $\frac{d(g \circ f)}{dx} = \frac{dg}{df} \frac{df}{dx}$.

... indefinite integrals ...

\begin{align*}
    \int S \spc dT := 
    \begin{cases}
        \Big( \int S_T \Big) \circ T_{\overline{S}} & \text{ $T$ is an eventual preferred letter of $S$} \\
        ST & \text{$T$ is not an eventual preferred letter of $S$}
    \end{cases}.
\end{align*}

note, in particular

\begin{align*}
    \int S \spc d\overline{S} = \Big( \int S_{\overline{S}} \Big) \circ \overline{S}_{\overline{\overline{S}}}.
\end{align*}

gives us change of variables theorem

\begin{mdframed}
    If $g$ and $f$ are functions, $f$ is the preferred letter of $g$, and $x$ is the preferred letter of $f$, then
       
    \begin{align*}
        \int g \frac{df}{dx} dx = \int g \spc df.
    \end{align*}
    
    [theorem restates $\int (g \circ f) f' = (\int g) \circ f$]
    
    [convention involving $\Phi$ required to interpret lhs integrand correctly]
    
    [rhs interpretation: $\int g \spc df = (\int g_f) \circ f_x = (\int g) \circ f$]
\end{mdframed}

(have to use second ``other syntactical rule'' for left integrand to make sense)

... definite integrals ...

\begin{align*}
    \int_a^b S \spc dT :=
    \begin{cases}
        \int_a^b S_T & T \neq \overline{S}, \text{ even when $T$ is not a preferred letter of $S$} \\
        \int_{\overline{S}(a)}^{\overline{S}(b)} S_{\overline{S}} & T = \overline{S}
    \end{cases}.
\end{align*}

this implies

\begin{align*}
    \int_a^b S \spc dT :=
    \begin{cases}
        \int_a^b S_T & T \neq \overline{S} \text{ and $T$ is a preferred letter of $S$} \\
        b - a & T \neq \overline{S} \text{ and $T$ is not a preferred letter of $S$} \\
        \int_{\overline{S}(a)}^{\overline{S}(b)} S_{\overline{S}} & T = \overline{S}
    \end{cases}.
\end{align*}

gives us change of variables theorem for definite integrals

\begin{mdframed}
    If $g$ and $f$ are functions, $f$ is the preferred letter of $g$, and $x$ is the preferred letter of $f$, then
        
    \begin{align*}
        \int_a^b g \frac{df}{dx} dx = \int_{f(a)}^{f(b)} g \spc df.
    \end{align*}
\end{mdframed}

\subsubsection*{The actual physicist's perspective on functions and the chain rule}

Unfortunately, many calculus and physics textbooks conflate functions with functions evaluated on inputs, and operate under the nonsensical convention that $S(T)$ should be interpreted to mean either $S_T$ or $S_T(T)$, depending on context. This can make things really confusing.

\subsection*{Properties of exponential functions}

[the sections regarding exponential functions and $e$ draw heavily from \url{https://paramanands.blogspot.com/2014/05/theories-of-exponential-and-logarithmic-functions-part-3.html#.YSz6iN9OlPY}]

Show $b^{x + y} = b^x b^y$ and that $x \mapsto b^x$ is continuous. For continuity, it suffices to show continuity at $x = 0$ and then use $b^{x + y} = b^x b^y$.

\subsection*{Justification that $e$ exists and other related technical facts}

Here, we prove that there is a real number $b > 0$ for which $\lim_{h \rightarrow 0} \frac{b^h - 1}{h} = 1$. Knowing this fact justifies defining $e$ to be the real number such that ${\Big( \frac{d}{dx} e^x \Big)\Big|_0 = \lim_{h \rightarrow 0} \frac{e^h - 1}{h} = 1}$.

In order to prove that there is a real number $b > 0$ for which $\lim_{h \rightarrow 0} \frac{b^h - 1}{h} = 1$, we will prove the following three facts:

\begin{enumerate}
    \item $\lim_{h \rightarrow 0} \frac{b^h - 1}{h}$ converges for all nonzero real numbers $b$.
    \item The function defined by $f(b) := \lim_{h \rightarrow 0} \frac{b^h - 1}{h}$ is invertible. In other words, 
    \begin{enumerate}
        \item[2.1.] $f$ is one-to-one.
        \item[2.2.] For every real number $y > 0$ there exists a real number $b > 0$ such that $y = f(b)$.
    \end{enumerate}
    \item $f^{-1}(1) > 0$.
\end{enumerate}

Before we prove (1), (2), or (3), first note that that $f(1) = 0$ and that $f$ is continuous wherever it is defined\footnote{$f$ is continuous wherever it is defined because $b \mapsto \frac{b^h - 1}{h}$ is a composition of continuous functions of $b$ and because $\lim_{b \rightarrow b_0}$ and $\lim_{h \rightarrow 0}$ commute.}. 

\vspace{.25cm}

Now we prove that these facts are true.

\begin{enumerate}
    \item ($\lim_{h \rightarrow 0} \frac{b^h - 1}{h}$ converges for all nonzero real numbers $b$).
    
    Clearly, the limit does not exist when $b = 0$. 
        
    First, we will show that the left-sided limit $\lim_{h \rightarrow 0^-} \frac{b^h - 1}{h}$ exists. Due to the monotone convergence theorem, we know that the left-sided limit must exist if it is the case that for all $b \neq 0$ the function $h \mapsto \frac{b^h - 1}{h}$ is bounded and monotone on $(0, 1) - \{0\}$. In the below we prove that this is indeed the case.
    
    \begin{itemize}
        \item (Monotonicity on $(0, 1) - \{0\}$). Using $a = h, r = \frac{1}{n}, s = \frac{1}{n + 1}$ in inequality (\ref{ineq2}), we see that for $b > 0$ the function $n \mapsto n(b^{\frac{1}{n}} - 1)$ is decreasing. Substituting $h = \frac{1}{n}$ shows that $h \mapsto \frac{b^h - 1}{h}$ is an increasing function for all $b > 0$. A similar argument shows that $h \mapsto \frac{b^h - 1}{h}$ is a decreasing function of $h$ for all $b < 0$. Thus $h \mapsto \frac{b^h - 1}{h}$ is monotone on $(0, 1) - \{0\}$.
        \item (Boundedness on $(0, 1)$). From inequality (\ref{ineq11}), we know that $b^{h - 1}(b - 1) < \frac{b^h - 1}{h} < b - 1$ for all $b > 1, h \in (0, 1)$. Thus $g$ is bounded on $(0, 1)$.
    \end{itemize}
    
    Now we show that the the left-sided limit is the same as the right-sided limit. Consider the left sided limit $\lim_{h \rightarrow 0^-} \frac{b^h - 1}{h}$, and substitute $k = -h$ so that $k \rightarrow 0^+$. We have
    
    \begin{align*}
        &\lim_{h \rightarrow 0^-} \Big( \frac{b^h - 1}{h} \Big) 
        = \lim_{k \rightarrow 0^+} \Big( \frac{b^{-k} - 1}{-k} \cdot \frac{b^k}{b^k} \Big) 
        = \lim_{k \rightarrow 0^+} \Big( \frac{1 - b^k}{-kb^k} \Big)
        = \lim_{k \rightarrow 0^+} \Big( \frac{b^k - 1}{kb^k} \Big) \\ 
        &= \frac{\lim_{k \rightarrow 0^+} \Big( \frac{b^k - 1}{k} \Big)}{\lim_{k \rightarrow 0^+} (b^k)}
        = \frac{\lim_{k \rightarrow 0^+} \Big( \frac{b^k - 1}{k} \Big)}{1}
        = \lim_{h \rightarrow 0^+} \Big( \frac{b^h - 1}{h} \Big).
    \end{align*}
    
    \item ($f$ is invertible).
    
    Recall from the above that $f$ is invertible if
    
    \begin{enumerate}
        \item[2.1.] $f$ is one-to-one.
        \item[2.2.] For every real number $y > 0$ there exists a real number $b > 0$ such that $y = f(b)$.
    \end{enumerate}
    
    We already know that $f$ is one-to-one because we showed that $f$ is monotone on our way to showing (1). So, we just need to show (2.2).
    
    In order to show (2.2), we'll need to first glean some inspiration from wishful thinking: if it \textit{were} true that $f$ was invertible, then we could follow the discussion of the earlier section ``Derivatives of exponential functions'' to obtain that $\frac{d}{dx} b^x = f(b) b^x = \log_e(b) b^x$, where $e := f^{-1}(1)$. So, we would have $f(b) = \log_e(b)$ for all nonzero $b$, i.e. $f = \log_e$.
    
    Now, we don't \textit{actually} know that $f$ is invertible, so we can't just assume that $f = \log_e$. However, what we \textit{can} do is try to show that $f$ satisfies properties of logarithms, and then try to use those properties to show that (2.2) is true.
    
    It's pretty straightforward to show that $f(ab) = f(a) + f(b)$ and $f(\frac{1}{b}) = -f(b)$ by using properties of limits. From this it follows that $f(b^x) = xf(b)$ for integer $x$.
        
    Now, we will use the fact that $f(b^x) = xf(b)$ for integer $x$ to show that $\lim_{b \rightarrow \infty} f(b) = \infty$ and $\lim_{b \rightarrow 0^+} f(b) = -\infty$. Once we know this, we are done, since if $\lim_{b \rightarrow 0^+} f(b) = -\infty$, $\lim_{b \rightarrow \infty} f(b) = \infty$, and as $f$ is continuous, then the intermediate value theorem guarantees that for every real number $y > 0$ there is a real number $b > 0$ such that $y = f(b)$.
    
    \begin{itemize}
        \item If we show that $\lim_{b \rightarrow \infty} f(b) = \infty$, then $\lim_{b \rightarrow 0^+} f(b) = -\infty$ follows because $f(\frac{1}{b}) = -f(b)$. Before we show $\lim_{b \rightarrow \infty} f(b) = \infty$, we need to show that $b \mapsto f(b)$ is increasing for $b > 1$.
        \begin{itemize}
            \item ($b \mapsto f(b)$ is increasing for $b > 1$). If $1 < a < b$ then $\frac{a}{b} < 1$, so $f(\frac{a}{b}) = f(a) - f(b) < 0$, which gives $f(a) < f(b)$.
        \end{itemize}
        \item ($\lim_{b \rightarrow \infty} f(b) = \infty$). Let $L > 0$. We need to show that there is a $b$ such that $f(b) > L$. 
            
        Choose any $a > 1$ so that $f(a) > 0$. Then $L = nf(a)$ for some integer $n > 0$. I.e., $L = nf(a) = f(a^n)$. Since $f$ is increasing for $b > 1$, and as $a^n > a > 1$, any $b > a^n$ will work: $f(b) > f(a^n) = L$.
    \end{itemize}
    \item To show that $f^{-1}(1) > 0$, it suffices to show that $f(b) > 0$ when $b > 1$.
    
    Since we know $b^{h - 1}(b - 1) < \frac{b^h - 1}{h} < (b - 1)$ from inequality (\ref{ineq11}), we can take limits of both sides and then use the continuity of $x \mapsto b^x$ to obtain $\frac{b - 1}{b} < f(b) < b - 1$. This shows that $f(b) > 0$ when $b > 1$.
\end{enumerate}

\subsection*{Inequalities}
    
Let $a > 1$ be a real number and let $r > 0$ be an integer. Since $a^r > a^i$ for each $i$, we have ${ra^r > 1 + a + a^2 + ... + a^{r - 1}}$. Multiply both sides by $a - 1 > 0$ and simplify to see $ra^r(a - 1) > a^r - 1$. Add $r(a^r - 1)$ to both sides and factor to get $r(a^{r + 1} - 1) > (r + 1)(a^r - 1)$. Thus $\frac{a^{r + 1} - 1}{r + 1} > \frac{a^r - 1}{r}$. A similar argument shows $\frac{1 - b^{r + 1}}{r + 1} < \frac{1 - b^r}{r}$ for all real numbers $b \in (0, 1)$. In all,

\begin{align}
    \label{ineq1}
    \frac{a^{r + 1} - 1}{r + 1} > \frac{a^r - 1}{r} \text{ and } \frac{1 - b^{r + 1}}{r + 1} < \frac{1 - b^r}{r},
\end{align} 

for all real numbers $a, b$ with $a > 1, b \in (0, 1)$ and for all integers $r, s$ with $0 < s < r$.

It follows that if $r, s$ are positive integers with $r > s$ then

\begin{align}
    \label{ineq2}
    \frac{a^r - 1}{r} > \frac{a^s - 1}{s} \text{ and } \frac{1 - b^r}{r} < \frac{1 - b^s}{s},
\end{align}

for all real numbers $a, b$ with $a > 1$ and $b \in (0, 1)$. 

These inequalities can be extended to hold for rational $r, s$ such that $0 < s < r$.

Use $s = 1$ in each equation from (\ref{ineq2}) to obtain the first line of the below, and $r = 1$ in each equation from (\ref{ineq2}) to obtain the second line of the below:

\begin{align}
    \label{ineq3}
    a^r - 1 > r(a - 1) &\text{ and } 1 - b^r < r(1 - b) \text{ for $r > 1$} \\
    \label{ineq4}
    a^s - 1 < s(a - 1) &\text{ and } 1 - b^s > s(1 - b) \text{ for $s \in (0, 1)$}.
\end{align}

Again consider $a > 1$ and $b \in (0, 1)$. Then $\frac{1}{a} \in (0, 1)$ and $b > 1$, so we can substitute $b = \frac{1}{a}$ and $a = \frac{1}{b}$ into the previous two inequalities. After simplifying, we obtain

\begin{align}
   \label{ineq5}
   a^r - 1 < r a^{r - 1}(a - 1) \text{ and } 1 - b^r > rb^{r - 1}(1 - b) \\
   \label{ineq6}
   a^s - 1 > sa^{s - 1}(a - 1) \text{ and } 1 - b^s < sb^{s - 1}(1 - b)
\end{align}

for all real numbers $a, b$ with $a > 1, b \in (0, 1)$ and all rational $r, s$ with $0 < s < r$.

Combining together the inequalities from (\ref{ineq3}), (\ref{ineq4}), (\ref{ineq5}), (\ref{ineq6}), (e.g. combine the first inequality of (\ref{ineq3}), which involves $a^r - 1$, with the first equation of (\ref{ineq5}), which also involves $a^r - 1$), we obtain

\begin{align}
    \label{ineq7}
    ra^{r - 1}(a - 1) > a^r - 1 > r(a - 1) \text{ and } sa^{s - 1}(a - 1) < a^s - 1 < s(a - 1) \\
    \label{ineq8}
    rb^{r - 1}(1 - b) < 1 - b^r < r(1 - b) \text{ and } sb^{s - 1}(1 - b) > 1 - b^s > s(1 - b).
\end{align}

for all $a, b \in \R$ with $a \in (0, 1), b > 1$ and for all rational $r, s$ with $r > 1, s \in (0, 1)$.

Multiplying each side of these inequalities by $-1$, we have

\begin{align}
    \label{ineq9}
    ra^{r - 1}(1 - a) < 1 - a^r < r(1 - a) \text{ and } sa^{s - 1}(1 - a) > 1- a^s > s(1 - a) \\
    \label{ineq10}
    rb^{r - 1}(b - 1) > b^r - 1 > r(b - 1) \text{ and } sb^{s - 1}(b - 1) < b^s - 1 < s(b - 1).
\end{align}

for all $a, b \in \R$ with $a \in (0, 1), b > 1$ and for all rational $r, s$ with $r > 1, s \in (0, 1)$.

Dividing the second equation of (\ref{ineq10}) by $s$, we have in particular that

\begin{align}
    \label{ineq11}
     b^{s - 1}(b - 1) < \frac{b^s - 1}{s} < b - 1 \text{ for all real $b > 1$ and rational $s \in (0, 1)$}.
\end{align}

\part*{Multivariable calculus}

\begin{itemize}
    \item Convention: $\frac{\pd f}{\pdx}, \frac{\pd f}{\pd y}, \frac{\pd f}{\pd z}$ almost always refer to the partial derivative of $f$ with respect to the first, second, or third argument, respectively.
    \item $\frac{\pd f}{\pd \vv}\Big|_{\xx_0} := \frac{df(\xx_0 + \vv t)}{dt}\Big|_{x = 0} = \Big( (\nabla f)|_{\xx_0 + \vv t} \cdot \vv \Big)\Big|_{x = 0} = (\nabla f) |_{\xx_0} \cdot \vv$. You might also see the definition $\frac{\pd f}{\pd \vv}\Big|_{\xx_0} := \lim_{h \rightarrow 0}\frac{f(\xx_0 + h \vv) - f(\xx_0)}{h}$. This is because $\frac{df(\xx_0 + \vv t)}{dt}\Big|_{x = 0} = \Big(\lim_{h \rightarrow 0} \frac{f(\xx_0 + (t + h) \vv) - f(\xx_0 + \vv t)}{h}\Big)\Big|_{x = 0} = \lim_{h \rightarrow 0}\frac{f(\xx_0 + h \vv) - f(\xx_0)}{h}$.
\end{itemize}



\end{document}
